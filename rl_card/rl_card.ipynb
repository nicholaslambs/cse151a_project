{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/mqmegatz/.local/lib/python3.9/site-packages (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "import rlcard\n",
    "\n",
    "from rlcard.agents import DQNAgent, RandomAgent\n",
    "from rlcard.utils import (\n",
    "    get_device,\n",
    "    set_seed,\n",
    "    tournament,\n",
    "    reorganize,\n",
    "    Logger,\n",
    "    plot_curve,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    \n",
    "def unblock():\n",
    "    sys.stdout = sys.__stdout__\n",
    "    \n",
    "# block()\n",
    "# print(\"HI\")\n",
    "# unblock()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Uno environment\n",
    "env = rlcard.make('uno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The paths for saving the logs and learning curves\n",
    "log_dir = './experiments/uno_dqn_result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(\n",
    "                 num_actions=env.num_actions,\n",
    "                 state_shape=env.state_shape[0],\n",
    "                 mlp_layers=[128,128], #changed to 128\n",
    "                 replay_memory_size=5000,\n",
    "                 update_target_estimator_every=100,\n",
    "                 epsilon_decay_steps=10000,\n",
    "                 learning_rate=0.0005,\n",
    "                 batch_size=32,\n",
    "                 device=device,\n",
    "                 save_path=log_dir,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of players\n",
    "num_players = 2\n",
    "\n",
    "# Set the players in the environment\n",
    "env.set_agents([agent] + [RandomAgent(env.num_actions) for _ in range(num_players - 1)])\n",
    "\n",
    "# Reset the environment\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Agent\n",
    "To train the agent, you will need to create a training loop. During each iteration of the loop, the agent makes a decision, the environment is updated, and the agent learns from the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward function for static moves on action cards, playing and drawing cards\n",
    "def adjust_rewards(trajectories, payoffs):\n",
    "    adjusted_trajectories = []\n",
    "    for traj in trajectories:\n",
    "        adjusted_traj = []\n",
    "        for state, action, reward, next_state, done in traj:\n",
    "            if action == 60:  # Draw a card\n",
    "                reward -= 1  # Penalty for drawing a card\n",
    "\n",
    "            elif action >= 0 and action <= 9:  # Red number cards\n",
    "                reward += 1\n",
    "            elif action >= 10 and action <= 12:  # Red action cards\n",
    "                reward += 3\n",
    "            elif action == 13:  # Red wild card\n",
    "                reward += 6\n",
    "            elif action == 14:  # Red wild and draw 4 card\n",
    "                reward += 10\n",
    "\n",
    "            elif action >= 15 and action <= 24:  # Green number cards\n",
    "                reward += 1\n",
    "            elif action >= 25 and action <= 27:  # Green action cards\n",
    "                reward += 3\n",
    "            elif action == 28:  # Green wild card\n",
    "                reward += 6\n",
    "            elif action == 29:  # Green wild and draw 4 card\n",
    "                reward += 10\n",
    "\n",
    "            elif action >= 30 and action <= 39:  # Blue number cards\n",
    "                reward += 1\n",
    "            elif action >= 40 and action <= 42:  # Blue action cards\n",
    "                reward += 3\n",
    "            elif action == 43:  # Blue wild card\n",
    "                reward += 6\n",
    "            elif action == 44:  # Blue wild and draw 4 card\n",
    "                reward += 10\n",
    "\n",
    "            elif action >= 45 and action <= 54:  # Yellow number cards\n",
    "                reward += 1\n",
    "            elif action >= 55 and action <= 57:  # Yellow action cards\n",
    "                reward += 3\n",
    "            elif action == 58:  # Yellow wild card\n",
    "                reward += 6\n",
    "            elif action == 59:  # Yellow wild and draw 4 card\n",
    "                reward += 10\n",
    "                \n",
    "            adjusted_traj.append((state, action, reward, next_state, done))\n",
    "        adjusted_trajectories.append(adjusted_traj)\n",
    "    return adjusted_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_rewards(trajectories, payoffs):\n",
    "    adjusted_trajectories = []\n",
    "    for traj in trajectories:\n",
    "        adjusted_traj = []\n",
    "        for state, action, reward, next_state, done in traj:\n",
    "            # Actual game state details\n",
    "            raw_obs = state['raw_obs']\n",
    "            \n",
    "            # Retrieve the number of cards in player's hand\n",
    "            num_cards_player = len(raw_obs['hand'])\n",
    "            \n",
    "            # Provide the number of cards for each player with the current player being index 0\n",
    "            num_cards_opponent = raw_obs['num_cards'][1] if raw_obs['current_player'] == 0 else raw_obs['num_cards'][0]\n",
    "\n",
    "            if action == 60:  # Draw a card\n",
    "                reward -= max(1, 3 - num_cards_player / 7)\n",
    "\n",
    "            # Adjust rewards for action cards based on the opponent's hand size\n",
    "            action_card_reward_multiplier = max(1, (7 - num_cards_opponent) / 7)\n",
    "\n",
    "            if action in range(10, 15) or action in range(25, 30) or action in range(40, 45) or action in range(55, 60):\n",
    "                reward += 2 * action_card_reward_multiplier\n",
    "\n",
    "            if action in range(0, 10) or action in range(15, 25) or action in range(30, 40) or action in range(45, 55):\n",
    "                reward += 1 + (3 - num_cards_player / 7)\n",
    "\n",
    "            adjusted_traj.append((state, action, reward, next_state, done))\n",
    "        adjusted_trajectories.append(adjusted_traj)\n",
    "    return adjusted_trajectories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building out the simulation\n",
    "\n",
    "Previously, the code would run an entire/complete simulation. However, this restricts the ability to learn from moves within the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/25000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 3183, rl-loss: 61.45465850830078\r",
      "INFO - Step 3184, rl-loss: 52.54437255859375\r",
      "INFO - Step 3185, rl-loss: 61.61508560180664\r",
      "INFO - Step 3186, rl-loss: 46.972389221191406\r",
      "INFO - Step 3187, rl-loss: 68.94454193115234\r",
      "INFO - Step 3188, rl-loss: 206.26991271972656\r",
      "INFO - Step 3189, rl-loss: 35.135711669921875\r",
      "INFO - Step 3190, rl-loss: 94.83740234375\r",
      "INFO - Step 3191, rl-loss: 40.110862731933594\r",
      "INFO - Step 3192, rl-loss: 43.160823822021484\r",
      "INFO - Step 3193, rl-loss: 216.81182861328125\r",
      "INFO - Step 3194, rl-loss: 241.00839233398438\r",
      "INFO - Step 3195, rl-loss: 190.69671630859375\r",
      "INFO - Step 3196, rl-loss: 162.21092224121094\r",
      "INFO - Step 3197, rl-loss: 277.01214599609375\r",
      "INFO - Step 3198, rl-loss: 44.337459564208984\r",
      "INFO - Step 3199, rl-loss: 45.88159942626953\r",
      "INFO - Step 3200, rl-loss: 187.46588134765625\r",
      "INFO - Step 3201, rl-loss: 225.4972381591797\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 3202, rl-loss: 61.76237487792969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/25000 [00:01<44:11,  9.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 3203, rl-loss: 73.74034881591797\r",
      "INFO - Step 3204, rl-loss: 129.84027099609375\r",
      "INFO - Step 3205, rl-loss: 59.21306610107422\r",
      "INFO - Step 3206, rl-loss: 200.42050170898438\r",
      "INFO - Step 3207, rl-loss: 105.14641571044922\r",
      "INFO - Step 3208, rl-loss: 87.26130676269531\r",
      "INFO - Step 3209, rl-loss: 243.77017211914062\r",
      "INFO - Step 3210, rl-loss: 346.0421142578125\r",
      "INFO - Step 3211, rl-loss: 43.248931884765625\r",
      "INFO - Step 3212, rl-loss: 198.2099609375\r",
      "INFO - Step 3213, rl-loss: 707.9168701171875\r",
      "INFO - Step 3214, rl-loss: 192.38290405273438\r",
      "INFO - Step 3215, rl-loss: 176.2235107421875\r",
      "INFO - Step 3216, rl-loss: 146.63587951660156\r",
      "INFO - Step 3217, rl-loss: 132.84085083007812\r",
      "INFO - Step 3218, rl-loss: 560.5632934570312\r",
      "INFO - Step 3219, rl-loss: 95.70018005371094\r",
      "INFO - Step 3220, rl-loss: 208.0276641845703\r",
      "INFO - Step 3221, rl-loss: 196.57847595214844\r",
      "INFO - Step 3222, rl-loss: 47.44309616088867\r",
      "INFO - Step 3223, rl-loss: 174.73789978027344\r",
      "INFO - Step 3224, rl-loss: 231.57675170898438\r",
      "INFO - Step 3225, rl-loss: 75.83135223388672\r",
      "INFO - Step 3226, rl-loss: 243.93161010742188\r",
      "INFO - Step 3227, rl-loss: 478.9802551269531\r",
      "INFO - Step 3228, rl-loss: 229.4152069091797\r",
      "INFO - Step 3229, rl-loss: 463.0969543457031\r",
      "INFO - Step 3230, rl-loss: 78.16300964355469\r",
      "INFO - Step 3231, rl-loss: 115.89820098876953\r",
      "INFO - Step 3232, rl-loss: 89.03363037109375\r",
      "INFO - Step 3233, rl-loss: 559.0419921875\r",
      "INFO - Step 3234, rl-loss: 87.25885009765625\r",
      "INFO - Step 3235, rl-loss: 224.3509521484375\r",
      "INFO - Step 3236, rl-loss: 152.20602416992188\r",
      "INFO - Step 3237, rl-loss: 34.46355438232422\r",
      "INFO - Step 3238, rl-loss: 44.93681716918945\r",
      "INFO - Step 3239, rl-loss: 206.39483642578125\r",
      "INFO - Step 3240, rl-loss: 279.942138671875\r",
      "INFO - Step 3241, rl-loss: 88.12925720214844\r",
      "INFO - Step 3242, rl-loss: 158.9198455810547\r",
      "INFO - Step 3243, rl-loss: 206.61480712890625\r",
      "INFO - Step 3244, rl-loss: 91.62255859375\r",
      "INFO - Step 3245, rl-loss: 57.582916259765625\r",
      "INFO - Step 3246, rl-loss: 48.499725341796875\r",
      "INFO - Step 3247, rl-loss: 65.38475036621094\r",
      "INFO - Step 3248, rl-loss: 49.27837371826172\r",
      "INFO - Step 3249, rl-loss: 113.63177490234375\r",
      "INFO - Step 3250, rl-loss: 243.73828125\r",
      "INFO - Step 3251, rl-loss: 50.8221549987793\r",
      "INFO - Step 3252, rl-loss: 191.6197509765625\r",
      "INFO - Step 3253, rl-loss: 384.66827392578125\r",
      "INFO - Step 3254, rl-loss: 471.135498046875\r",
      "INFO - Step 3255, rl-loss: 485.76416015625\r",
      "INFO - Step 3256, rl-loss: 213.91213989257812\r",
      "INFO - Step 3257, rl-loss: 62.59437561035156\r",
      "INFO - Step 3258, rl-loss: 519.029052734375\r",
      "INFO - Step 3259, rl-loss: 110.4570083618164\r",
      "INFO - Step 3260, rl-loss: 181.8006591796875\r",
      "INFO - Step 3261, rl-loss: 368.6292724609375\r",
      "INFO - Step 3262, rl-loss: 170.73004150390625\r",
      "INFO - Step 3263, rl-loss: 233.74417114257812\r",
      "INFO - Step 3264, rl-loss: 41.973419189453125\r",
      "INFO - Step 3265, rl-loss: 350.22576904296875\r",
      "INFO - Step 3266, rl-loss: 329.41632080078125\r",
      "INFO - Step 3267, rl-loss: 232.72157287597656\r",
      "INFO - Step 3268, rl-loss: 86.28901672363281\r",
      "INFO - Step 3269, rl-loss: 47.33715057373047\r",
      "INFO - Step 3270, rl-loss: 183.13238525390625\r",
      "INFO - Step 3271, rl-loss: 71.82327270507812\r",
      "INFO - Step 3272, rl-loss: 215.74139404296875\r",
      "INFO - Step 3273, rl-loss: 213.11141967773438\r",
      "INFO - Step 3274, rl-loss: 197.1347198486328\r",
      "INFO - Step 3275, rl-loss: 374.925048828125\r",
      "INFO - Step 3276, rl-loss: 53.169586181640625\r",
      "INFO - Step 3277, rl-loss: 444.2716369628906\r",
      "INFO - Step 3278, rl-loss: 611.5449829101562\r",
      "INFO - Step 3279, rl-loss: 114.45165252685547\r",
      "INFO - Step 3280, rl-loss: 212.02874755859375\r",
      "INFO - Step 3281, rl-loss: 46.900299072265625\r",
      "INFO - Step 3282, rl-loss: 70.15557861328125\r",
      "INFO - Step 3283, rl-loss: 190.3073272705078\r",
      "INFO - Step 3284, rl-loss: 55.07936096191406\r",
      "INFO - Step 3285, rl-loss: 194.873046875\r",
      "INFO - Step 3286, rl-loss: 615.1847534179688\r",
      "INFO - Step 3287, rl-loss: 745.97509765625\r",
      "INFO - Step 3288, rl-loss: 205.99630737304688\r",
      "INFO - Step 3289, rl-loss: 226.1735382080078\r",
      "INFO - Step 3290, rl-loss: 370.2402038574219\r",
      "INFO - Step 3291, rl-loss: 30.39284896850586\r",
      "INFO - Step 3292, rl-loss: 211.10125732421875\r",
      "INFO - Step 3293, rl-loss: 32.812828063964844\r",
      "INFO - Step 3294, rl-loss: 66.78771209716797\r",
      "INFO - Step 3295, rl-loss: 73.15481567382812\r",
      "INFO - Step 3296, rl-loss: 113.58346557617188\r",
      "INFO - Step 3297, rl-loss: 28.683876037597656\r",
      "INFO - Step 3298, rl-loss: 63.23862075805664\r",
      "INFO - Step 3299, rl-loss: 365.19830322265625\r",
      "INFO - Step 3300, rl-loss: 53.27049255371094\r",
      "INFO - Step 3301, rl-loss: 244.0892791748047\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 3302, rl-loss: 57.184635162353516\r",
      "INFO - Step 3303, rl-loss: 394.1683349609375\r",
      "INFO - Step 3304, rl-loss: 181.60865783691406\r",
      "INFO - Step 3305, rl-loss: 48.027915954589844\r",
      "INFO - Step 3306, rl-loss: 160.30941772460938\r",
      "INFO - Step 3307, rl-loss: 164.576904296875\r",
      "INFO - Step 3308, rl-loss: 44.40132522583008\r",
      "INFO - Step 3309, rl-loss: 171.16958618164062\r",
      "INFO - Step 3310, rl-loss: 70.25529479980469\r",
      "INFO - Step 3311, rl-loss: 57.88709259033203\r",
      "INFO - Step 3312, rl-loss: 187.15306091308594\r",
      "INFO - Step 3313, rl-loss: 86.85198974609375\r",
      "INFO - Step 3314, rl-loss: 50.95747375488281\r",
      "INFO - Step 3315, rl-loss: 219.3892822265625\r",
      "INFO - Step 3316, rl-loss: 157.59840393066406\r",
      "INFO - Step 3317, rl-loss: 237.7325439453125\r",
      "INFO - Step 3318, rl-loss: 74.92064666748047\r",
      "INFO - Step 3319, rl-loss: 51.03727722167969\r",
      "INFO - Step 3320, rl-loss: 249.1471710205078\r",
      "INFO - Step 3321, rl-loss: 240.85934448242188\r",
      "INFO - Step 3322, rl-loss: 120.56295776367188\r",
      "INFO - Step 3323, rl-loss: 184.4316864013672\r",
      "INFO - Step 3324, rl-loss: 153.4651641845703\r",
      "INFO - Step 3325, rl-loss: 50.59324645996094\r",
      "INFO - Step 3326, rl-loss: 55.507110595703125\r",
      "INFO - Step 3327, rl-loss: 293.21929931640625\r",
      "INFO - Step 3328, rl-loss: 51.963375091552734\r",
      "INFO - Step 3329, rl-loss: 60.00478744506836\r",
      "INFO - Step 3330, rl-loss: 253.99713134765625\r",
      "INFO - Step 3331, rl-loss: 184.6862030029297\r",
      "INFO - Step 3332, rl-loss: 351.56011962890625\r",
      "INFO - Step 3333, rl-loss: 352.5617370605469\r",
      "INFO - Step 3334, rl-loss: 191.16539001464844\r",
      "INFO - Step 3335, rl-loss: 53.631690979003906\r",
      "INFO - Step 3336, rl-loss: 253.97030639648438\r",
      "INFO - Step 3337, rl-loss: 308.7506103515625\r",
      "INFO - Step 3338, rl-loss: 27.58368492126465\r",
      "INFO - Step 3339, rl-loss: 41.743980407714844\r",
      "INFO - Step 3340, rl-loss: 65.49986267089844\r",
      "INFO - Step 3341, rl-loss: 69.53389739990234\r",
      "INFO - Step 3342, rl-loss: 249.73013305664062\r",
      "INFO - Step 3343, rl-loss: 299.9864807128906\r",
      "INFO - Step 3344, rl-loss: 80.92774200439453\r",
      "INFO - Step 3345, rl-loss: 189.13369750976562\r",
      "INFO - Step 3346, rl-loss: 47.488433837890625\r",
      "INFO - Step 3347, rl-loss: 118.4421615600586\r",
      "INFO - Step 3348, rl-loss: 40.320247650146484\r",
      "INFO - Step 3349, rl-loss: 25.912918090820312\r",
      "INFO - Step 3350, rl-loss: 39.82412338256836\r",
      "INFO - Step 3351, rl-loss: 75.84500122070312\r",
      "INFO - Step 3352, rl-loss: 37.369319915771484\r",
      "INFO - Step 3353, rl-loss: 319.9356384277344\r",
      "INFO - Step 3354, rl-loss: 177.83627319335938\r",
      "INFO - Step 3355, rl-loss: 303.45001220703125\r",
      "INFO - Step 3356, rl-loss: 348.03955078125\r",
      "INFO - Step 3357, rl-loss: 65.01985168457031\r",
      "INFO - Step 3358, rl-loss: 67.47350311279297\r",
      "INFO - Step 3359, rl-loss: 267.83636474609375\r",
      "INFO - Step 3360, rl-loss: 49.03593063354492\r",
      "INFO - Step 3361, rl-loss: 55.90055465698242\r",
      "INFO - Step 3362, rl-loss: 101.26507568359375\r",
      "INFO - Step 3363, rl-loss: 234.21798706054688\r",
      "INFO - Step 3364, rl-loss: 33.11729431152344\r",
      "INFO - Step 3365, rl-loss: 66.27688598632812\r",
      "INFO - Step 3366, rl-loss: 475.0775451660156\r",
      "INFO - Step 3367, rl-loss: 345.6552734375\r",
      "INFO - Step 3368, rl-loss: 31.915966033935547\r",
      "INFO - Step 3369, rl-loss: 133.6219482421875\r",
      "INFO - Step 3370, rl-loss: 198.6188201904297\r",
      "INFO - Step 3371, rl-loss: 500.1170654296875\r",
      "INFO - Step 3372, rl-loss: 54.017459869384766\r",
      "INFO - Step 3373, rl-loss: 337.6831359863281\r",
      "INFO - Step 3374, rl-loss: 318.180908203125\r",
      "INFO - Step 3375, rl-loss: 105.00597381591797\r",
      "INFO - Step 3376, rl-loss: 186.4130859375\r",
      "INFO - Step 3377, rl-loss: 335.0767517089844\r",
      "INFO - Step 3378, rl-loss: 87.60693359375\r",
      "INFO - Step 3379, rl-loss: 493.3310546875\r",
      "INFO - Step 3380, rl-loss: 211.65647888183594\r",
      "INFO - Step 3381, rl-loss: 68.14537048339844\r",
      "INFO - Step 3382, rl-loss: 62.540313720703125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/25000 [00:02<32:36, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 3383, rl-loss: 48.911170959472656\r",
      "INFO - Step 3384, rl-loss: 118.4203872680664\r",
      "INFO - Step 3385, rl-loss: 550.7944946289062\r",
      "INFO - Step 3386, rl-loss: 227.14694213867188\r",
      "INFO - Step 3387, rl-loss: 147.84756469726562\r",
      "INFO - Step 3388, rl-loss: 38.971923828125\r",
      "INFO - Step 3389, rl-loss: 438.03192138671875\r",
      "INFO - Step 3390, rl-loss: 357.01702880859375\r",
      "INFO - Step 3391, rl-loss: 405.2966613769531\r",
      "INFO - Step 3392, rl-loss: 40.974365234375\r",
      "INFO - Step 3393, rl-loss: 40.986026763916016\r",
      "INFO - Step 3394, rl-loss: 103.07438659667969\r",
      "INFO - Step 3395, rl-loss: 229.79039001464844\r",
      "INFO - Step 3396, rl-loss: 161.78677368164062\r",
      "INFO - Step 3397, rl-loss: 49.19243621826172\r",
      "INFO - Step 3398, rl-loss: 104.63958740234375\r",
      "INFO - Step 3399, rl-loss: 86.70748901367188\r",
      "INFO - Step 3400, rl-loss: 89.76404571533203\r",
      "INFO - Step 3401, rl-loss: 41.978851318359375\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 3402, rl-loss: 190.33401489257812\r",
      "INFO - Step 3403, rl-loss: 122.64781188964844\r",
      "INFO - Step 3404, rl-loss: 47.942901611328125\r",
      "INFO - Step 3405, rl-loss: 136.7321319580078\r",
      "INFO - Step 3406, rl-loss: 212.92295837402344\r",
      "INFO - Step 3407, rl-loss: 385.59417724609375\r",
      "INFO - Step 3408, rl-loss: 78.40151977539062\r",
      "INFO - Step 3409, rl-loss: 69.60063171386719\r",
      "INFO - Step 3410, rl-loss: 147.62022399902344\r",
      "INFO - Step 3411, rl-loss: 434.1800537109375\r",
      "INFO - Step 3412, rl-loss: 291.2388000488281\r",
      "INFO - Step 3413, rl-loss: 47.87913513183594\r",
      "INFO - Step 3414, rl-loss: 54.09176254272461\r",
      "INFO - Step 3415, rl-loss: 157.1301727294922\r",
      "INFO - Step 3416, rl-loss: 92.86382293701172\r",
      "INFO - Step 3417, rl-loss: 95.15975952148438\r",
      "INFO - Step 3418, rl-loss: 183.57313537597656\r",
      "INFO - Step 3419, rl-loss: 193.03981018066406\r",
      "INFO - Step 3420, rl-loss: 58.95222091674805\r",
      "INFO - Step 3421, rl-loss: 108.19300079345703\r",
      "INFO - Step 3422, rl-loss: 250.1396942138672\r",
      "INFO - Step 3423, rl-loss: 61.809349060058594\r",
      "INFO - Step 3424, rl-loss: 86.727294921875\r",
      "INFO - Step 3425, rl-loss: 245.87794494628906\r",
      "INFO - Step 3426, rl-loss: 200.744873046875\r",
      "INFO - Step 3427, rl-loss: 68.90995788574219\r",
      "INFO - Step 3428, rl-loss: 67.76223754882812\r",
      "INFO - Step 3429, rl-loss: 43.98295593261719\r",
      "INFO - Step 3430, rl-loss: 56.74708938598633\r",
      "INFO - Step 3431, rl-loss: 372.4942321777344\r",
      "INFO - Step 3432, rl-loss: 283.7763671875\r",
      "INFO - Step 3433, rl-loss: 54.16790008544922\r",
      "INFO - Step 3434, rl-loss: 247.0358428955078\r",
      "INFO - Step 3435, rl-loss: 423.90093994140625\r",
      "INFO - Step 3436, rl-loss: 180.2208251953125\r",
      "INFO - Step 3437, rl-loss: 434.57391357421875\r",
      "INFO - Step 3438, rl-loss: 178.4231719970703\r",
      "INFO - Step 3439, rl-loss: 40.66636657714844\r",
      "INFO - Step 3440, rl-loss: 164.4503631591797\r",
      "INFO - Step 3441, rl-loss: 186.19151306152344\r",
      "INFO - Step 3442, rl-loss: 230.94346618652344\r",
      "INFO - Step 3443, rl-loss: 28.120864868164062\r",
      "INFO - Step 3444, rl-loss: 252.7650146484375\r",
      "INFO - Step 3445, rl-loss: 240.84483337402344\r",
      "INFO - Step 3446, rl-loss: 115.59300231933594\r",
      "INFO - Step 3447, rl-loss: 191.29940795898438\r",
      "INFO - Step 3448, rl-loss: 290.7426452636719\r",
      "INFO - Step 3449, rl-loss: 289.6968078613281\r",
      "INFO - Step 3450, rl-loss: 269.05670166015625\r",
      "INFO - Step 3451, rl-loss: 45.10006332397461\r",
      "INFO - Step 3452, rl-loss: 17.984148025512695\r",
      "INFO - Step 3453, rl-loss: 57.24276351928711\r",
      "INFO - Step 3454, rl-loss: 150.67501831054688\r",
      "INFO - Step 3455, rl-loss: 26.868480682373047\r",
      "INFO - Step 3456, rl-loss: 35.820030212402344\r",
      "INFO - Step 3457, rl-loss: 128.72256469726562\r",
      "INFO - Step 3458, rl-loss: 221.24659729003906\r",
      "INFO - Step 3459, rl-loss: 77.40723419189453\r",
      "INFO - Step 3460, rl-loss: 51.35368728637695\r",
      "INFO - Step 3461, rl-loss: 77.38977813720703\r",
      "INFO - Step 3462, rl-loss: 141.72332763671875\r",
      "INFO - Step 3463, rl-loss: 191.59347534179688\r",
      "INFO - Step 3464, rl-loss: 231.1123504638672\r",
      "INFO - Step 3465, rl-loss: 67.04850769042969\r",
      "INFO - Step 3466, rl-loss: 352.401611328125\r",
      "INFO - Step 3467, rl-loss: 250.15072631835938\r",
      "INFO - Step 3468, rl-loss: 196.4391632080078\r",
      "INFO - Step 3469, rl-loss: 463.17431640625\r",
      "INFO - Step 3470, rl-loss: 70.31318664550781\r",
      "INFO - Step 3471, rl-loss: 56.604698181152344\r",
      "INFO - Step 3472, rl-loss: 24.868850708007812\r",
      "INFO - Step 3473, rl-loss: 218.27557373046875\r",
      "INFO - Step 3474, rl-loss: 68.68965911865234\r",
      "INFO - Step 3475, rl-loss: 231.8351287841797\r",
      "INFO - Step 3476, rl-loss: 56.439064025878906\r",
      "INFO - Step 3477, rl-loss: 83.27467346191406\r",
      "INFO - Step 3478, rl-loss: 133.51034545898438\r",
      "INFO - Step 3479, rl-loss: 41.07211685180664\r",
      "INFO - Step 3480, rl-loss: 71.70081329345703\r",
      "INFO - Step 3481, rl-loss: 222.02659606933594\r",
      "INFO - Step 3482, rl-loss: 146.0691375732422\r",
      "INFO - Step 3483, rl-loss: 46.6898307800293\r",
      "INFO - Step 3484, rl-loss: 412.08807373046875\r",
      "INFO - Step 3485, rl-loss: 72.05401611328125\r",
      "INFO - Step 3486, rl-loss: 71.69833374023438\r",
      "INFO - Step 3487, rl-loss: 290.92852783203125\r",
      "INFO - Step 3488, rl-loss: 269.9062805175781\r",
      "INFO - Step 3489, rl-loss: 119.7175064086914\r",
      "INFO - Step 3490, rl-loss: 144.87066650390625\r",
      "INFO - Step 3491, rl-loss: 119.37383270263672\r",
      "INFO - Step 3492, rl-loss: 61.411766052246094\r",
      "INFO - Step 3493, rl-loss: 305.958984375\r",
      "INFO - Step 3494, rl-loss: 42.08618927001953\r",
      "INFO - Step 3495, rl-loss: 52.531253814697266\r",
      "INFO - Step 3496, rl-loss: 52.268768310546875\r",
      "INFO - Step 3497, rl-loss: 219.43917846679688\r",
      "INFO - Step 3498, rl-loss: 188.9741973876953\r",
      "INFO - Step 3499, rl-loss: 86.2473373413086\r",
      "INFO - Step 3500, rl-loss: 176.48414611816406\r",
      "INFO - Step 3501, rl-loss: 234.7035369873047\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 3502, rl-loss: 82.63799285888672\r",
      "INFO - Step 3503, rl-loss: 78.45677185058594\r",
      "INFO - Step 3504, rl-loss: 220.10980224609375\r",
      "INFO - Step 3505, rl-loss: 37.440101623535156\r",
      "INFO - Step 3506, rl-loss: 240.1179656982422\r",
      "INFO - Step 3507, rl-loss: 190.03244018554688\r",
      "INFO - Step 3508, rl-loss: 180.4588165283203\r",
      "INFO - Step 3509, rl-loss: 373.6664123535156\r",
      "INFO - Step 3510, rl-loss: 181.6656494140625\r",
      "INFO - Step 3511, rl-loss: 463.4876708984375\r",
      "INFO - Step 3512, rl-loss: 98.46844482421875\r",
      "INFO - Step 3513, rl-loss: 49.69178771972656\r",
      "INFO - Step 3514, rl-loss: 72.0904541015625\r",
      "INFO - Step 3515, rl-loss: 152.99652099609375\r",
      "INFO - Step 3516, rl-loss: 173.30392456054688\r",
      "INFO - Step 3517, rl-loss: 45.34306335449219\r",
      "INFO - Step 3518, rl-loss: 96.7625732421875\r",
      "INFO - Step 3519, rl-loss: 296.83441162109375\r",
      "INFO - Step 3520, rl-loss: 56.65915298461914\r",
      "INFO - Step 3521, rl-loss: 223.76028442382812\r",
      "INFO - Step 3522, rl-loss: 330.06744384765625\r",
      "INFO - Step 3523, rl-loss: 52.989524841308594\r",
      "INFO - Step 3524, rl-loss: 162.71917724609375\r",
      "INFO - Step 3525, rl-loss: 50.23152160644531\r",
      "INFO - Step 3526, rl-loss: 236.662109375\r",
      "INFO - Step 3527, rl-loss: 89.08686828613281\r",
      "INFO - Step 3528, rl-loss: 105.80146789550781\r",
      "INFO - Step 3529, rl-loss: 190.2005157470703\r",
      "INFO - Step 3530, rl-loss: 211.43487548828125\r",
      "INFO - Step 3531, rl-loss: 42.15839385986328\r",
      "INFO - Step 3532, rl-loss: 220.3432159423828\r",
      "INFO - Step 3533, rl-loss: 92.76876068115234\r",
      "INFO - Step 3534, rl-loss: 85.37628173828125\r",
      "INFO - Step 3535, rl-loss: 81.99217987060547\r",
      "INFO - Step 3536, rl-loss: 61.41972351074219\r",
      "INFO - Step 3537, rl-loss: 66.25405883789062\r",
      "INFO - Step 3538, rl-loss: 92.97626495361328\r",
      "INFO - Step 3539, rl-loss: 166.07443237304688\r",
      "INFO - Step 3540, rl-loss: 58.4919319152832\r",
      "INFO - Step 3541, rl-loss: 193.15533447265625\r",
      "INFO - Step 3542, rl-loss: 77.94510650634766\r",
      "INFO - Step 3543, rl-loss: 495.47698974609375\r",
      "INFO - Step 3544, rl-loss: 133.57594299316406\r",
      "INFO - Step 3545, rl-loss: 211.18115234375\r",
      "INFO - Step 3546, rl-loss: 137.68544006347656\r",
      "INFO - Step 3547, rl-loss: 40.628353118896484\r",
      "INFO - Step 3548, rl-loss: 48.24811553955078\r",
      "INFO - Step 3549, rl-loss: 62.231136322021484\r",
      "INFO - Step 3550, rl-loss: 39.157005310058594\r",
      "INFO - Step 3551, rl-loss: 371.06573486328125\r",
      "INFO - Step 3552, rl-loss: 510.83575439453125\r",
      "INFO - Step 3553, rl-loss: 111.06712341308594\r",
      "INFO - Step 3554, rl-loss: 38.3658447265625\r",
      "INFO - Step 3555, rl-loss: 141.17112731933594\r",
      "INFO - Step 3556, rl-loss: 245.9464111328125\r",
      "INFO - Step 3557, rl-loss: 110.22193145751953\r",
      "INFO - Step 3558, rl-loss: 298.3968505859375\r",
      "INFO - Step 3559, rl-loss: 263.1411437988281\r",
      "INFO - Step 3560, rl-loss: 209.32281494140625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/25000 [00:03<39:20, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 3561, rl-loss: 192.22271728515625\r",
      "INFO - Step 3562, rl-loss: 151.12863159179688\r",
      "INFO - Step 3563, rl-loss: 48.768104553222656\r",
      "INFO - Step 3564, rl-loss: 357.47930908203125\r",
      "INFO - Step 3565, rl-loss: 61.47281265258789\r",
      "INFO - Step 3566, rl-loss: 67.99372100830078\r",
      "INFO - Step 3567, rl-loss: 126.28960418701172\r",
      "INFO - Step 3568, rl-loss: 58.43463897705078\r",
      "INFO - Step 3569, rl-loss: 64.36871337890625\r",
      "INFO - Step 3570, rl-loss: 48.2669563293457\r",
      "INFO - Step 3571, rl-loss: 140.428466796875\r",
      "INFO - Step 3572, rl-loss: 76.96734619140625\r",
      "INFO - Step 3573, rl-loss: 489.9808044433594\r",
      "INFO - Step 3574, rl-loss: 98.49095916748047\r",
      "INFO - Step 3575, rl-loss: 309.6670837402344\r",
      "INFO - Step 3576, rl-loss: 74.231689453125\r",
      "INFO - Step 3577, rl-loss: 153.03309631347656\r",
      "INFO - Step 3578, rl-loss: 476.0849914550781\r",
      "INFO - Step 3579, rl-loss: 127.99111938476562\r",
      "INFO - Step 3580, rl-loss: 370.2466125488281\r",
      "INFO - Step 3581, rl-loss: 275.98846435546875\r",
      "INFO - Step 3582, rl-loss: 234.46435546875\r",
      "INFO - Step 3583, rl-loss: 66.8713607788086\r",
      "INFO - Step 3584, rl-loss: 146.8937530517578\r",
      "INFO - Step 3585, rl-loss: 49.42146301269531\r",
      "INFO - Step 3586, rl-loss: 192.78826904296875\r",
      "INFO - Step 3587, rl-loss: 246.53460693359375\r",
      "INFO - Step 3588, rl-loss: 79.84770202636719\r",
      "INFO - Step 3589, rl-loss: 98.86761474609375\r",
      "INFO - Step 3590, rl-loss: 167.61514282226562\r",
      "INFO - Step 3591, rl-loss: 339.025634765625\r",
      "INFO - Step 3592, rl-loss: 301.77215576171875\r",
      "INFO - Step 3593, rl-loss: 49.29035949707031\r",
      "INFO - Step 3594, rl-loss: 88.11167907714844\r",
      "INFO - Step 3595, rl-loss: 171.34732055664062\r",
      "INFO - Step 3596, rl-loss: 80.05943298339844\r",
      "INFO - Step 3597, rl-loss: 66.80305480957031\r",
      "INFO - Step 3598, rl-loss: 157.73452758789062\r",
      "INFO - Step 3599, rl-loss: 80.66175842285156\r",
      "INFO - Step 3600, rl-loss: 339.48834228515625\r",
      "INFO - Step 3601, rl-loss: 235.23509216308594\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 3602, rl-loss: 117.58879852294922\r",
      "INFO - Step 3603, rl-loss: 174.172607421875\r",
      "INFO - Step 3604, rl-loss: 362.3069152832031\r",
      "INFO - Step 3605, rl-loss: 205.2418212890625\r",
      "INFO - Step 3606, rl-loss: 74.59873962402344\r",
      "INFO - Step 3607, rl-loss: 66.03868103027344\r",
      "INFO - Step 3608, rl-loss: 232.2769775390625\r",
      "INFO - Step 3609, rl-loss: 215.54751586914062\r",
      "INFO - Step 3610, rl-loss: 48.13787078857422\r",
      "INFO - Step 3611, rl-loss: 70.37165832519531\r",
      "INFO - Step 3612, rl-loss: 74.49083709716797\r",
      "INFO - Step 3613, rl-loss: 355.7618103027344\r",
      "INFO - Step 3614, rl-loss: 51.70740509033203\r",
      "INFO - Step 3615, rl-loss: 81.81200408935547\r",
      "INFO - Step 3616, rl-loss: 53.411827087402344\r",
      "INFO - Step 3617, rl-loss: 105.65238189697266\r",
      "INFO - Step 3618, rl-loss: 363.37213134765625\r",
      "INFO - Step 3619, rl-loss: 75.30725860595703\r",
      "INFO - Step 3620, rl-loss: 47.47977828979492\r",
      "INFO - Step 3621, rl-loss: 232.48130798339844\r",
      "INFO - Step 3622, rl-loss: 100.40864562988281\r",
      "INFO - Step 3623, rl-loss: 79.32996368408203\r",
      "INFO - Step 3624, rl-loss: 315.91973876953125\r",
      "INFO - Step 3625, rl-loss: 363.15142822265625\r",
      "INFO - Step 3626, rl-loss: 70.70306396484375\r",
      "INFO - Step 3627, rl-loss: 64.80693817138672\r",
      "INFO - Step 3628, rl-loss: 40.85251998901367\r",
      "INFO - Step 3629, rl-loss: 99.07292175292969\r",
      "INFO - Step 3630, rl-loss: 140.7522735595703\r",
      "INFO - Step 3631, rl-loss: 91.47966766357422\r",
      "INFO - Step 3632, rl-loss: 59.07890701293945\r",
      "INFO - Step 3633, rl-loss: 296.93310546875\r",
      "INFO - Step 3634, rl-loss: 204.87904357910156\r",
      "INFO - Step 3635, rl-loss: 100.09508514404297\r",
      "INFO - Step 3636, rl-loss: 221.3417510986328\r",
      "INFO - Step 3637, rl-loss: 51.06920623779297\r",
      "INFO - Step 3638, rl-loss: 52.26215744018555\r",
      "INFO - Step 3639, rl-loss: 43.75429916381836\r",
      "INFO - Step 3640, rl-loss: 456.09478759765625\r",
      "INFO - Step 3641, rl-loss: 182.3671112060547\r",
      "INFO - Step 3642, rl-loss: 35.18170928955078\r",
      "INFO - Step 3643, rl-loss: 432.7669677734375\r",
      "INFO - Step 3644, rl-loss: 176.2727813720703\r",
      "INFO - Step 3645, rl-loss: 110.05322265625\r",
      "INFO - Step 3646, rl-loss: 77.67134094238281\r",
      "INFO - Step 3647, rl-loss: 271.86785888671875\r",
      "INFO - Step 3648, rl-loss: 48.42491912841797\r",
      "INFO - Step 3649, rl-loss: 126.3599853515625\r",
      "INFO - Step 3650, rl-loss: 471.9498291015625\r",
      "INFO - Step 3651, rl-loss: 35.27562713623047\r",
      "INFO - Step 3652, rl-loss: 105.59120178222656\r",
      "INFO - Step 3653, rl-loss: 99.91455078125\r",
      "INFO - Step 3654, rl-loss: 312.2881164550781\r",
      "INFO - Step 3655, rl-loss: 242.38040161132812\r",
      "INFO - Step 3656, rl-loss: 197.04635620117188\r",
      "INFO - Step 3657, rl-loss: 64.45088195800781\r",
      "INFO - Step 3658, rl-loss: 37.04608917236328\r",
      "INFO - Step 3659, rl-loss: 124.1091537475586\r",
      "INFO - Step 3660, rl-loss: 238.66392517089844\r",
      "INFO - Step 3661, rl-loss: 259.607421875\r",
      "INFO - Step 3662, rl-loss: 67.81269836425781\r",
      "INFO - Step 3663, rl-loss: 51.66535186767578\r",
      "INFO - Step 3664, rl-loss: 295.3253479003906\r",
      "INFO - Step 3665, rl-loss: 108.96926879882812\r",
      "INFO - Step 3666, rl-loss: 48.703495025634766\r",
      "INFO - Step 3667, rl-loss: 454.00738525390625\r",
      "INFO - Step 3668, rl-loss: 270.42852783203125\r",
      "INFO - Step 3669, rl-loss: 90.33850860595703\r",
      "INFO - Step 3670, rl-loss: 332.542236328125\r",
      "INFO - Step 3671, rl-loss: 55.744911193847656\r",
      "INFO - Step 3672, rl-loss: 124.82113647460938\r",
      "INFO - Step 3673, rl-loss: 36.10356521606445\r",
      "INFO - Step 3674, rl-loss: 420.16314697265625\r",
      "INFO - Step 3675, rl-loss: 112.54067993164062\r",
      "INFO - Step 3676, rl-loss: 44.78196716308594\r",
      "INFO - Step 3677, rl-loss: 67.04022216796875\r",
      "INFO - Step 3678, rl-loss: 26.473114013671875\r",
      "INFO - Step 3679, rl-loss: 73.96926879882812\r",
      "INFO - Step 3680, rl-loss: 374.6424560546875\r",
      "INFO - Step 3681, rl-loss: 52.95413589477539\r",
      "INFO - Step 3682, rl-loss: 140.489013671875\r",
      "INFO - Step 3683, rl-loss: 316.65203857421875\r",
      "INFO - Step 3684, rl-loss: 86.18585205078125\r",
      "INFO - Step 3685, rl-loss: 206.30841064453125\r",
      "INFO - Step 3686, rl-loss: 70.76976776123047\r",
      "INFO - Step 3687, rl-loss: 121.98193359375\r",
      "INFO - Step 3688, rl-loss: 233.04867553710938\r",
      "INFO - Step 3689, rl-loss: 222.50375366210938\r",
      "INFO - Step 3690, rl-loss: 64.91880798339844\r",
      "INFO - Step 3691, rl-loss: 199.92977905273438\r",
      "INFO - Step 3692, rl-loss: 73.06767272949219\r",
      "INFO - Step 3693, rl-loss: 184.34768676757812\r",
      "INFO - Step 3694, rl-loss: 180.83493041992188\r",
      "INFO - Step 3695, rl-loss: 135.37940979003906\r",
      "INFO - Step 3696, rl-loss: 215.95993041992188\r",
      "INFO - Step 3697, rl-loss: 56.25132369995117\r",
      "INFO - Step 3698, rl-loss: 381.7466125488281\r",
      "INFO - Step 3699, rl-loss: 230.61557006835938\r",
      "INFO - Step 3700, rl-loss: 181.68125915527344\r",
      "INFO - Step 3701, rl-loss: 254.98202514648438\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 3702, rl-loss: 203.19363403320312\r",
      "INFO - Step 3703, rl-loss: 399.4082336425781\r",
      "INFO - Step 3704, rl-loss: 88.8695068359375\r",
      "INFO - Step 3705, rl-loss: 71.8323745727539\r",
      "INFO - Step 3706, rl-loss: 83.636962890625\r",
      "INFO - Step 3707, rl-loss: 164.120361328125\r",
      "INFO - Step 3708, rl-loss: 80.24008178710938\r",
      "INFO - Step 3709, rl-loss: 340.328369140625\r",
      "INFO - Step 3710, rl-loss: 352.7161865234375\r",
      "INFO - Step 3711, rl-loss: 197.6212615966797\r",
      "INFO - Step 3712, rl-loss: 60.00092315673828\r",
      "INFO - Step 3713, rl-loss: 130.10069274902344\r",
      "INFO - Step 3714, rl-loss: 61.379852294921875\r",
      "INFO - Step 3715, rl-loss: 165.0038604736328\r",
      "INFO - Step 3716, rl-loss: 248.33181762695312\r",
      "INFO - Step 3717, rl-loss: 122.8326416015625\r",
      "INFO - Step 3718, rl-loss: 200.5147705078125\r",
      "INFO - Step 3719, rl-loss: 250.17910766601562\r",
      "INFO - Step 3720, rl-loss: 364.857421875\r",
      "INFO - Step 3721, rl-loss: 122.93904113769531\r",
      "INFO - Step 3722, rl-loss: 323.1827392578125\r",
      "INFO - Step 3723, rl-loss: 129.3212127685547\r",
      "INFO - Step 3724, rl-loss: 170.8921661376953\r",
      "INFO - Step 3725, rl-loss: 146.88015747070312\r",
      "INFO - Step 3726, rl-loss: 33.18244171142578\r",
      "INFO - Step 3727, rl-loss: 207.2974853515625\r",
      "INFO - Step 3728, rl-loss: 56.65958023071289\r",
      "INFO - Step 3729, rl-loss: 79.63424682617188\r",
      "INFO - Step 3730, rl-loss: 109.75065612792969\r",
      "INFO - Step 3731, rl-loss: 85.8023681640625\r",
      "INFO - Step 3732, rl-loss: 77.8227310180664\r",
      "INFO - Step 3733, rl-loss: 212.33554077148438\r",
      "INFO - Step 3734, rl-loss: 360.7080383300781\r",
      "INFO - Step 3735, rl-loss: 40.32016372680664\r",
      "INFO - Step 3736, rl-loss: 106.44222259521484\r",
      "INFO - Step 3737, rl-loss: 37.293148040771484\r",
      "INFO - Step 3738, rl-loss: 229.02249145507812\r",
      "INFO - Step 3739, rl-loss: 273.5757141113281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/25000 [00:04<37:22, 11.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 3740, rl-loss: 342.9959716796875\r",
      "INFO - Step 3741, rl-loss: 482.5440673828125\r",
      "INFO - Step 3742, rl-loss: 75.27110290527344\r",
      "INFO - Step 3743, rl-loss: 57.358978271484375\r",
      "INFO - Step 3744, rl-loss: 149.8240203857422\r",
      "INFO - Step 3745, rl-loss: 124.48252868652344\r",
      "INFO - Step 3746, rl-loss: 210.42501831054688\r",
      "INFO - Step 3747, rl-loss: 227.38778686523438\r",
      "INFO - Step 3748, rl-loss: 239.8907012939453\r",
      "INFO - Step 3749, rl-loss: 168.64248657226562\r",
      "INFO - Step 3750, rl-loss: 165.64697265625\r",
      "INFO - Step 3751, rl-loss: 193.8618621826172\r",
      "INFO - Step 3752, rl-loss: 36.38011169433594\r",
      "INFO - Step 3753, rl-loss: 62.08038330078125\r",
      "INFO - Step 3754, rl-loss: 43.509178161621094\r",
      "INFO - Step 3755, rl-loss: 61.96166229248047\r",
      "INFO - Step 3756, rl-loss: 52.86485290527344\r",
      "INFO - Step 3757, rl-loss: 61.58356475830078\r",
      "INFO - Step 3758, rl-loss: 59.322078704833984\r",
      "INFO - Step 3759, rl-loss: 48.08494186401367\r",
      "INFO - Step 3760, rl-loss: 92.36627197265625\r",
      "INFO - Step 3761, rl-loss: 192.25025939941406\r",
      "INFO - Step 3762, rl-loss: 96.80300903320312\r",
      "INFO - Step 3763, rl-loss: 164.10174560546875\r",
      "INFO - Step 3764, rl-loss: 428.616455078125\r",
      "INFO - Step 3765, rl-loss: 147.35755920410156\r",
      "INFO - Step 3766, rl-loss: 85.19317626953125\r",
      "INFO - Step 3767, rl-loss: 408.38897705078125\r",
      "INFO - Step 3768, rl-loss: 209.79359436035156\r",
      "INFO - Step 3769, rl-loss: 284.19635009765625\r",
      "INFO - Step 3770, rl-loss: 238.56790161132812\r",
      "INFO - Step 3771, rl-loss: 157.60153198242188\r",
      "INFO - Step 3772, rl-loss: 221.04605102539062\r",
      "INFO - Step 3773, rl-loss: 92.66880798339844\r",
      "INFO - Step 3774, rl-loss: 167.0428466796875\r",
      "INFO - Step 3775, rl-loss: 407.4548645019531\r",
      "INFO - Step 3776, rl-loss: 59.016902923583984\r",
      "INFO - Step 3777, rl-loss: 69.37184143066406\r",
      "INFO - Step 3778, rl-loss: 307.27484130859375\r",
      "INFO - Step 3779, rl-loss: 50.976539611816406\r",
      "INFO - Step 3780, rl-loss: 48.72893524169922\r",
      "INFO - Step 3781, rl-loss: 179.7347869873047\r",
      "INFO - Step 3782, rl-loss: 83.57264709472656\r",
      "INFO - Step 3783, rl-loss: 288.31829833984375\r",
      "INFO - Step 3784, rl-loss: 575.4966430664062\r",
      "INFO - Step 3785, rl-loss: 136.94602966308594\r",
      "INFO - Step 3786, rl-loss: 75.88412475585938\r",
      "INFO - Step 3787, rl-loss: 134.6173095703125\r",
      "INFO - Step 3788, rl-loss: 350.20489501953125\r",
      "INFO - Step 3789, rl-loss: 59.805992126464844\r",
      "INFO - Step 3790, rl-loss: 111.69432067871094\r",
      "INFO - Step 3791, rl-loss: 54.318016052246094\r",
      "INFO - Step 3792, rl-loss: 302.10980224609375\r",
      "INFO - Step 3793, rl-loss: 171.78097534179688\r",
      "INFO - Step 3794, rl-loss: 241.6761016845703\r",
      "INFO - Step 3795, rl-loss: 43.61289978027344\r",
      "INFO - Step 3796, rl-loss: 246.68336486816406\r",
      "INFO - Step 3797, rl-loss: 430.078857421875\r",
      "INFO - Step 3798, rl-loss: 90.76014709472656\r",
      "INFO - Step 3799, rl-loss: 230.72335815429688\r",
      "INFO - Step 3800, rl-loss: 76.24232482910156\r",
      "INFO - Step 3801, rl-loss: 66.88581848144531\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 3802, rl-loss: 507.65411376953125\r",
      "INFO - Step 3803, rl-loss: 43.096649169921875\r",
      "INFO - Step 3804, rl-loss: 48.327362060546875\r",
      "INFO - Step 3805, rl-loss: 73.11531066894531\r",
      "INFO - Step 3806, rl-loss: 66.55318450927734\r",
      "INFO - Step 3807, rl-loss: 81.64273071289062\r",
      "INFO - Step 3808, rl-loss: 193.7357177734375\r",
      "INFO - Step 3809, rl-loss: 146.85055541992188\r",
      "INFO - Step 3810, rl-loss: 73.68221282958984\r",
      "INFO - Step 3811, rl-loss: 429.4986877441406\r",
      "INFO - Step 3812, rl-loss: 183.76239013671875\r",
      "INFO - Step 3813, rl-loss: 131.563232421875\r",
      "INFO - Step 3814, rl-loss: 189.48782348632812\r",
      "INFO - Step 3815, rl-loss: 45.765647888183594\r",
      "INFO - Step 3816, rl-loss: 206.1137237548828\r",
      "INFO - Step 3817, rl-loss: 207.58993530273438\r",
      "INFO - Step 3818, rl-loss: 237.34657287597656\r",
      "INFO - Step 3819, rl-loss: 45.35381317138672\r",
      "INFO - Step 3820, rl-loss: 103.31742858886719\r",
      "INFO - Step 3821, rl-loss: 351.9552307128906\r",
      "INFO - Step 3822, rl-loss: 80.75123596191406\r",
      "INFO - Step 3823, rl-loss: 349.66876220703125\r",
      "INFO - Step 3824, rl-loss: 247.1999053955078\r",
      "INFO - Step 3825, rl-loss: 243.64578247070312\r",
      "INFO - Step 3826, rl-loss: 201.29946899414062\r",
      "INFO - Step 3827, rl-loss: 80.26132202148438\r",
      "INFO - Step 3828, rl-loss: 206.62054443359375\r",
      "INFO - Step 3829, rl-loss: 88.09129333496094\r",
      "INFO - Step 3830, rl-loss: 36.51451110839844\r",
      "INFO - Step 3831, rl-loss: 80.43975830078125\r",
      "INFO - Step 3832, rl-loss: 84.20376586914062\r",
      "INFO - Step 3833, rl-loss: 53.09484100341797\r",
      "INFO - Step 3834, rl-loss: 54.32233428955078\r",
      "INFO - Step 3835, rl-loss: 371.13897705078125\r",
      "INFO - Step 3836, rl-loss: 182.07522583007812\r",
      "INFO - Step 3837, rl-loss: 174.4634246826172\r",
      "INFO - Step 3838, rl-loss: 93.03279113769531\r",
      "INFO - Step 3839, rl-loss: 37.97032928466797\r",
      "INFO - Step 3840, rl-loss: 59.2132682800293\r",
      "INFO - Step 3841, rl-loss: 212.3094482421875\r",
      "INFO - Step 3842, rl-loss: 314.5448303222656\r",
      "INFO - Step 3843, rl-loss: 224.29978942871094\r",
      "INFO - Step 3844, rl-loss: 106.4460220336914\r",
      "INFO - Step 3845, rl-loss: 133.73614501953125\r",
      "INFO - Step 3846, rl-loss: 374.58331298828125\r",
      "INFO - Step 3847, rl-loss: 96.97825622558594\r",
      "INFO - Step 3848, rl-loss: 79.58405303955078\r",
      "INFO - Step 3849, rl-loss: 224.1774139404297\r",
      "INFO - Step 3850, rl-loss: 250.50973510742188\r",
      "INFO - Step 3851, rl-loss: 82.03582763671875\r",
      "INFO - Step 3852, rl-loss: 107.04798889160156\r",
      "INFO - Step 3853, rl-loss: 202.87232971191406\r",
      "INFO - Step 3854, rl-loss: 177.021240234375\r",
      "INFO - Step 3855, rl-loss: 109.53802490234375\r",
      "INFO - Step 3856, rl-loss: 86.55462646484375\r",
      "INFO - Step 3857, rl-loss: 55.99852752685547\r",
      "INFO - Step 3858, rl-loss: 180.2525634765625\r",
      "INFO - Step 3859, rl-loss: 177.03256225585938\r",
      "INFO - Step 3860, rl-loss: 364.1755065917969\r",
      "INFO - Step 3861, rl-loss: 88.53453063964844\r",
      "INFO - Step 3862, rl-loss: 58.71074295043945\r",
      "INFO - Step 3863, rl-loss: 171.59756469726562\r",
      "INFO - Step 3864, rl-loss: 177.31317138671875\r",
      "INFO - Step 3865, rl-loss: 248.75396728515625\r",
      "INFO - Step 3866, rl-loss: 124.54772186279297\r",
      "INFO - Step 3867, rl-loss: 59.321163177490234\r",
      "INFO - Step 3868, rl-loss: 265.68609619140625\r",
      "INFO - Step 3869, rl-loss: 65.8993148803711\r",
      "INFO - Step 3870, rl-loss: 88.0303955078125\r",
      "INFO - Step 3871, rl-loss: 93.74363708496094\r",
      "INFO - Step 3872, rl-loss: 261.877197265625\r",
      "INFO - Step 3873, rl-loss: 98.43500518798828\r",
      "INFO - Step 3874, rl-loss: 462.61651611328125\r",
      "INFO - Step 3875, rl-loss: 80.87808990478516\r",
      "INFO - Step 3876, rl-loss: 117.77922821044922\r",
      "INFO - Step 3877, rl-loss: 44.411155700683594\r",
      "INFO - Step 3878, rl-loss: 83.74261474609375\r",
      "INFO - Step 3879, rl-loss: 206.4127960205078\r",
      "INFO - Step 3880, rl-loss: 184.25010681152344\r",
      "INFO - Step 3881, rl-loss: 79.0172119140625\r",
      "INFO - Step 3882, rl-loss: 271.35455322265625\r",
      "INFO - Step 3883, rl-loss: 208.80715942382812\r",
      "INFO - Step 3884, rl-loss: 568.4283447265625\r",
      "INFO - Step 3885, rl-loss: 68.99772644042969\r",
      "INFO - Step 3886, rl-loss: 166.86883544921875\r",
      "INFO - Step 3887, rl-loss: 39.13901901245117\r",
      "INFO - Step 3888, rl-loss: 82.6184310913086\r",
      "INFO - Step 3889, rl-loss: 63.693603515625\r",
      "INFO - Step 3890, rl-loss: 103.49793243408203\r",
      "INFO - Step 3891, rl-loss: 188.62472534179688\r",
      "INFO - Step 3892, rl-loss: 62.8126106262207\r",
      "INFO - Step 3893, rl-loss: 315.0855407714844\r",
      "INFO - Step 3894, rl-loss: 78.46241760253906\r",
      "INFO - Step 3895, rl-loss: 231.68618774414062\r",
      "INFO - Step 3896, rl-loss: 180.92112731933594\r",
      "INFO - Step 3897, rl-loss: 249.04090881347656\r",
      "INFO - Step 3898, rl-loss: 35.124366760253906\r",
      "INFO - Step 3899, rl-loss: 217.86627197265625\r",
      "INFO - Step 3900, rl-loss: 238.91729736328125\r",
      "INFO - Step 3901, rl-loss: 312.2124328613281\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 3902, rl-loss: 315.80596923828125\r",
      "INFO - Step 3903, rl-loss: 234.05015563964844\r",
      "INFO - Step 3904, rl-loss: 302.75982666015625\r",
      "INFO - Step 3905, rl-loss: 217.13832092285156\r",
      "INFO - Step 3906, rl-loss: 225.0260009765625\r",
      "INFO - Step 3907, rl-loss: 37.02524948120117\r",
      "INFO - Step 3908, rl-loss: 93.9163589477539\r",
      "INFO - Step 3909, rl-loss: 32.54924011230469\r",
      "INFO - Step 3910, rl-loss: 88.75836181640625\r",
      "INFO - Step 3911, rl-loss: 55.215354919433594\r",
      "INFO - Step 3912, rl-loss: 226.10252380371094\r",
      "INFO - Step 3913, rl-loss: 397.94970703125\r",
      "INFO - Step 3914, rl-loss: 41.93498229980469\r",
      "INFO - Step 3915, rl-loss: 77.77748107910156\r",
      "INFO - Step 3916, rl-loss: 305.27099609375\r",
      "INFO - Step 3917, rl-loss: 174.45802307128906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 46/25000 [00:05<34:43, 11.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 3918, rl-loss: 252.39883422851562\r",
      "INFO - Step 3919, rl-loss: 41.38932800292969\r",
      "INFO - Step 3920, rl-loss: 199.69204711914062\r",
      "INFO - Step 3921, rl-loss: 169.75173950195312\r",
      "INFO - Step 3922, rl-loss: 57.714881896972656\r",
      "INFO - Step 3923, rl-loss: 152.70709228515625\r",
      "INFO - Step 3924, rl-loss: 239.3529510498047\r",
      "INFO - Step 3925, rl-loss: 189.63259887695312\r",
      "INFO - Step 3926, rl-loss: 202.63015747070312\r",
      "INFO - Step 3927, rl-loss: 202.241943359375\r",
      "INFO - Step 3928, rl-loss: 310.81298828125\r",
      "INFO - Step 3929, rl-loss: 59.19672393798828\r",
      "INFO - Step 3930, rl-loss: 394.26995849609375\r",
      "INFO - Step 3931, rl-loss: 60.45562744140625\r",
      "INFO - Step 3932, rl-loss: 179.05245971679688\r",
      "INFO - Step 3933, rl-loss: 51.398216247558594\r",
      "INFO - Step 3934, rl-loss: 56.61960220336914\r",
      "INFO - Step 3935, rl-loss: 99.94207000732422\r",
      "INFO - Step 3936, rl-loss: 310.3231506347656\r",
      "INFO - Step 3937, rl-loss: 216.7433319091797\r",
      "INFO - Step 3938, rl-loss: 441.2132873535156\r",
      "INFO - Step 3939, rl-loss: 383.5748596191406\r",
      "INFO - Step 3940, rl-loss: 95.99586486816406\r",
      "INFO - Step 3941, rl-loss: 349.22332763671875\r",
      "INFO - Step 3942, rl-loss: 311.379150390625\r",
      "INFO - Step 3943, rl-loss: 57.46818161010742\r",
      "INFO - Step 3944, rl-loss: 77.99836730957031\r",
      "INFO - Step 3945, rl-loss: 130.41934204101562\r",
      "INFO - Step 3946, rl-loss: 162.7859649658203\r",
      "INFO - Step 3947, rl-loss: 175.07240295410156\r",
      "INFO - Step 3948, rl-loss: 112.27241516113281\r",
      "INFO - Step 3949, rl-loss: 61.26953887939453\r",
      "INFO - Step 3950, rl-loss: 181.98812866210938\r",
      "INFO - Step 3951, rl-loss: 79.98231506347656\r",
      "INFO - Step 3952, rl-loss: 40.540618896484375\r",
      "INFO - Step 3953, rl-loss: 75.00869750976562\r",
      "INFO - Step 3954, rl-loss: 250.90126037597656\r",
      "INFO - Step 3955, rl-loss: 47.07441711425781\r",
      "INFO - Step 3956, rl-loss: 51.626914978027344\r",
      "INFO - Step 3957, rl-loss: 311.7877502441406\r",
      "INFO - Step 3958, rl-loss: 97.27365112304688\r",
      "INFO - Step 3959, rl-loss: 273.003662109375\r",
      "INFO - Step 3960, rl-loss: 62.84590148925781\r",
      "INFO - Step 3961, rl-loss: 279.6669921875\r",
      "INFO - Step 3962, rl-loss: 47.354530334472656\r",
      "INFO - Step 3963, rl-loss: 188.56610107421875\r",
      "INFO - Step 3964, rl-loss: 227.43527221679688\r",
      "INFO - Step 3965, rl-loss: 58.80559539794922\r",
      "INFO - Step 3966, rl-loss: 142.45623779296875\r",
      "INFO - Step 3967, rl-loss: 41.096683502197266\r",
      "INFO - Step 3968, rl-loss: 288.7083740234375\r",
      "INFO - Step 3969, rl-loss: 52.13006591796875\r",
      "INFO - Step 3970, rl-loss: 329.6066589355469\r",
      "INFO - Step 3971, rl-loss: 277.59765625\r",
      "INFO - Step 3972, rl-loss: 67.46553039550781\r",
      "INFO - Step 3973, rl-loss: 197.789794921875\r",
      "INFO - Step 3974, rl-loss: 205.8134002685547\r",
      "INFO - Step 3975, rl-loss: 137.48260498046875\r",
      "INFO - Step 3976, rl-loss: 328.6404724121094\r",
      "INFO - Step 3977, rl-loss: 257.2117919921875\r",
      "INFO - Step 3978, rl-loss: 86.47293090820312\r",
      "INFO - Step 3979, rl-loss: 120.2276840209961\r",
      "INFO - Step 3980, rl-loss: 51.980350494384766\r",
      "INFO - Step 3981, rl-loss: 372.02984619140625\r",
      "INFO - Step 3982, rl-loss: 104.09989929199219\r",
      "INFO - Step 3983, rl-loss: 251.19912719726562\r",
      "INFO - Step 3984, rl-loss: 194.42147827148438\r",
      "INFO - Step 3985, rl-loss: 81.63417053222656\r",
      "INFO - Step 3986, rl-loss: 100.7949447631836\r",
      "INFO - Step 3987, rl-loss: 161.2933349609375\r",
      "INFO - Step 3988, rl-loss: 423.7477111816406\r",
      "INFO - Step 3989, rl-loss: 224.11793518066406\r",
      "INFO - Step 3990, rl-loss: 235.65757751464844\r",
      "INFO - Step 3991, rl-loss: 61.345184326171875\r",
      "INFO - Step 3992, rl-loss: 79.1576919555664\r",
      "INFO - Step 3993, rl-loss: 178.9852752685547\r",
      "INFO - Step 3994, rl-loss: 181.7416229248047\r",
      "INFO - Step 3995, rl-loss: 135.88909912109375\r",
      "INFO - Step 3996, rl-loss: 70.02235412597656\r",
      "INFO - Step 3997, rl-loss: 233.36651611328125\r",
      "INFO - Step 3998, rl-loss: 37.950984954833984\r",
      "INFO - Step 3999, rl-loss: 231.16769409179688\r",
      "INFO - Step 4000, rl-loss: 53.643402099609375\r",
      "INFO - Step 4001, rl-loss: 151.55035400390625\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4002, rl-loss: 62.404666900634766\r",
      "INFO - Step 4003, rl-loss: 43.35633850097656\r",
      "INFO - Step 4004, rl-loss: 233.38580322265625\r",
      "INFO - Step 4005, rl-loss: 70.43366241455078\r",
      "INFO - Step 4006, rl-loss: 337.0607604980469\r",
      "INFO - Step 4007, rl-loss: 66.3248062133789\r",
      "INFO - Step 4008, rl-loss: 34.751686096191406\r",
      "INFO - Step 4009, rl-loss: 75.63165283203125\r",
      "INFO - Step 4010, rl-loss: 60.23652267456055\r",
      "INFO - Step 4011, rl-loss: 89.75186920166016\r",
      "INFO - Step 4012, rl-loss: 46.06360626220703\r",
      "INFO - Step 4013, rl-loss: 237.34490966796875\r",
      "INFO - Step 4014, rl-loss: 60.68427276611328\r",
      "INFO - Step 4015, rl-loss: 278.0677795410156\r",
      "INFO - Step 4016, rl-loss: 195.08926391601562\r",
      "INFO - Step 4017, rl-loss: 221.927490234375\r",
      "INFO - Step 4018, rl-loss: 138.36917114257812\r",
      "INFO - Step 4019, rl-loss: 74.06668853759766\r",
      "INFO - Step 4020, rl-loss: 330.4441223144531\r",
      "INFO - Step 4021, rl-loss: 248.33004760742188\r",
      "INFO - Step 4022, rl-loss: 51.679500579833984\r",
      "INFO - Step 4023, rl-loss: 189.173095703125\r",
      "INFO - Step 4024, rl-loss: 95.1361083984375\r",
      "INFO - Step 4025, rl-loss: 250.45440673828125\r",
      "INFO - Step 4026, rl-loss: 142.5576934814453\r",
      "INFO - Step 4027, rl-loss: 366.3086853027344\r",
      "INFO - Step 4028, rl-loss: 538.168212890625\r",
      "INFO - Step 4029, rl-loss: 96.71639251708984\r",
      "INFO - Step 4030, rl-loss: 104.62213134765625\r",
      "INFO - Step 4031, rl-loss: 293.86041259765625\r",
      "INFO - Step 4032, rl-loss: 173.26834106445312\r",
      "INFO - Step 4033, rl-loss: 44.047584533691406\r",
      "INFO - Step 4034, rl-loss: 249.01002502441406\r",
      "INFO - Step 4035, rl-loss: 346.23516845703125\r",
      "INFO - Step 4036, rl-loss: 237.32986450195312\r",
      "INFO - Step 4037, rl-loss: 219.59317016601562\r",
      "INFO - Step 4038, rl-loss: 63.92621612548828\r",
      "INFO - Step 4039, rl-loss: 59.5062255859375\r",
      "INFO - Step 4040, rl-loss: 277.19036865234375\r",
      "INFO - Step 4041, rl-loss: 97.7846908569336\r",
      "INFO - Step 4042, rl-loss: 49.100894927978516\r",
      "INFO - Step 4043, rl-loss: 109.18402099609375\r",
      "INFO - Step 4044, rl-loss: 204.2396240234375\r",
      "INFO - Step 4045, rl-loss: 41.67650604248047\r",
      "INFO - Step 4046, rl-loss: 206.63575744628906\r",
      "INFO - Step 4047, rl-loss: 216.81610107421875\r",
      "INFO - Step 4048, rl-loss: 148.56857299804688\r",
      "INFO - Step 4049, rl-loss: 321.90325927734375\r",
      "INFO - Step 4050, rl-loss: 126.49090576171875\r",
      "INFO - Step 4051, rl-loss: 122.41400909423828\r",
      "INFO - Step 4052, rl-loss: 204.22793579101562\r",
      "INFO - Step 4053, rl-loss: 347.73583984375\r",
      "INFO - Step 4054, rl-loss: 52.97644805908203\r",
      "INFO - Step 4055, rl-loss: 67.77853393554688\r",
      "INFO - Step 4056, rl-loss: 312.80584716796875\r",
      "INFO - Step 4057, rl-loss: 81.61316680908203\r",
      "INFO - Step 4058, rl-loss: 368.44659423828125\r",
      "INFO - Step 4059, rl-loss: 89.72515869140625\r",
      "INFO - Step 4060, rl-loss: 51.14256286621094\r",
      "INFO - Step 4061, rl-loss: 94.42589569091797\r",
      "INFO - Step 4062, rl-loss: 152.7402801513672\r",
      "INFO - Step 4063, rl-loss: 52.08329772949219\r",
      "INFO - Step 4064, rl-loss: 223.04678344726562\r",
      "INFO - Step 4065, rl-loss: 205.12872314453125\r",
      "INFO - Step 4066, rl-loss: 223.33128356933594\r",
      "INFO - Step 4067, rl-loss: 50.017513275146484\r",
      "INFO - Step 4068, rl-loss: 36.29497146606445\r",
      "INFO - Step 4069, rl-loss: 192.97012329101562\r",
      "INFO - Step 4070, rl-loss: 100.30392456054688\r",
      "INFO - Step 4071, rl-loss: 77.17506408691406\r",
      "INFO - Step 4072, rl-loss: 66.57066345214844\r",
      "INFO - Step 4073, rl-loss: 138.5501708984375\r",
      "INFO - Step 4074, rl-loss: 432.1418762207031\r",
      "INFO - Step 4075, rl-loss: 214.34454345703125\r",
      "INFO - Step 4076, rl-loss: 73.04493713378906\r",
      "INFO - Step 4077, rl-loss: 372.8416442871094\r",
      "INFO - Step 4078, rl-loss: 237.54718017578125\r",
      "INFO - Step 4079, rl-loss: 274.1768493652344\r",
      "INFO - Step 4080, rl-loss: 234.71612548828125\r",
      "INFO - Step 4081, rl-loss: 166.77239990234375\r",
      "INFO - Step 4082, rl-loss: 86.13990020751953\r",
      "INFO - Step 4083, rl-loss: 212.8018035888672\r",
      "INFO - Step 4084, rl-loss: 65.0069580078125\r",
      "INFO - Step 4085, rl-loss: 48.50385284423828\r",
      "INFO - Step 4086, rl-loss: 184.48509216308594\r",
      "INFO - Step 4087, rl-loss: 82.82363891601562\r",
      "INFO - Step 4088, rl-loss: 375.4656982421875\r",
      "INFO - Step 4089, rl-loss: 143.0608673095703\r",
      "INFO - Step 4090, rl-loss: 43.747154235839844\r",
      "INFO - Step 4091, rl-loss: 437.92608642578125\r",
      "INFO - Step 4092, rl-loss: 299.48150634765625\r",
      "INFO - Step 4093, rl-loss: 223.64605712890625\r",
      "INFO - Step 4094, rl-loss: 495.23724365234375\r",
      "INFO - Step 4095, rl-loss: 69.24505615234375\r",
      "INFO - Step 4096, rl-loss: 253.13278198242188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 53/25000 [00:05<28:53, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 4097, rl-loss: 87.38688659667969\r",
      "INFO - Step 4098, rl-loss: 314.84527587890625\r",
      "INFO - Step 4099, rl-loss: 35.81758117675781\r",
      "INFO - Step 4100, rl-loss: 174.98086547851562\r",
      "INFO - Step 4101, rl-loss: 145.16552734375\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4102, rl-loss: 128.6160125732422\r",
      "INFO - Step 4103, rl-loss: 79.06996154785156\r",
      "INFO - Step 4104, rl-loss: 414.7591857910156\r",
      "INFO - Step 4105, rl-loss: 160.8731231689453\r",
      "INFO - Step 4106, rl-loss: 89.5592041015625\r",
      "INFO - Step 4107, rl-loss: 71.30786895751953\r",
      "INFO - Step 4108, rl-loss: 81.4061279296875\r",
      "INFO - Step 4109, rl-loss: 138.80532836914062\r",
      "INFO - Step 4110, rl-loss: 72.788330078125\r",
      "INFO - Step 4111, rl-loss: 78.43595886230469\r",
      "INFO - Step 4112, rl-loss: 160.55068969726562\r",
      "INFO - Step 4113, rl-loss: 51.728729248046875\r",
      "INFO - Step 4114, rl-loss: 118.01020812988281\r",
      "INFO - Step 4115, rl-loss: 311.61236572265625\r",
      "INFO - Step 4116, rl-loss: 214.94631958007812\r",
      "INFO - Step 4117, rl-loss: 46.59010696411133\r",
      "INFO - Step 4118, rl-loss: 285.400634765625\r",
      "INFO - Step 4119, rl-loss: 330.11151123046875\r",
      "INFO - Step 4120, rl-loss: 333.2704162597656\r",
      "INFO - Step 4121, rl-loss: 378.6686706542969\r",
      "INFO - Step 4122, rl-loss: 178.6780548095703\r",
      "INFO - Step 4123, rl-loss: 106.13931274414062\r",
      "INFO - Step 4124, rl-loss: 72.88531494140625\r",
      "INFO - Step 4125, rl-loss: 33.973628997802734\r",
      "INFO - Step 4126, rl-loss: 175.2918701171875\r",
      "INFO - Step 4127, rl-loss: 346.0476379394531\r",
      "INFO - Step 4128, rl-loss: 419.4969787597656\r",
      "INFO - Step 4129, rl-loss: 87.40643310546875\r",
      "INFO - Step 4130, rl-loss: 364.8773498535156\r",
      "INFO - Step 4131, rl-loss: 224.83335876464844\r",
      "INFO - Step 4132, rl-loss: 77.09217834472656\r",
      "INFO - Step 4133, rl-loss: 70.36238098144531\r",
      "INFO - Step 4134, rl-loss: 292.21868896484375\r",
      "INFO - Step 4135, rl-loss: 77.970703125\r",
      "INFO - Step 4136, rl-loss: 44.537078857421875\r",
      "INFO - Step 4137, rl-loss: 54.798370361328125\r",
      "INFO - Step 4138, rl-loss: 67.68687438964844\r",
      "INFO - Step 4139, rl-loss: 98.5963363647461\r",
      "INFO - Step 4140, rl-loss: 84.07269287109375\r",
      "INFO - Step 4141, rl-loss: 102.23301696777344\r",
      "INFO - Step 4142, rl-loss: 68.03564453125\r",
      "INFO - Step 4143, rl-loss: 187.90725708007812\r",
      "INFO - Step 4144, rl-loss: 221.61935424804688\r",
      "INFO - Step 4145, rl-loss: 332.6716003417969\r",
      "INFO - Step 4146, rl-loss: 257.4410400390625\r",
      "INFO - Step 4147, rl-loss: 70.86273193359375\r",
      "INFO - Step 4148, rl-loss: 55.668113708496094\r",
      "INFO - Step 4149, rl-loss: 105.23106384277344\r",
      "INFO - Step 4150, rl-loss: 259.2347412109375\r",
      "INFO - Step 4151, rl-loss: 207.8363037109375\r",
      "INFO - Step 4152, rl-loss: 193.32125854492188\r",
      "INFO - Step 4153, rl-loss: 82.9813003540039\r",
      "INFO - Step 4154, rl-loss: 312.12738037109375\r",
      "INFO - Step 4155, rl-loss: 232.10897827148438\r",
      "INFO - Step 4156, rl-loss: 223.20562744140625\r",
      "INFO - Step 4157, rl-loss: 164.32972717285156\r",
      "INFO - Step 4158, rl-loss: 175.92822265625\r",
      "INFO - Step 4159, rl-loss: 113.28665161132812\r",
      "INFO - Step 4160, rl-loss: 435.08349609375\r",
      "INFO - Step 4161, rl-loss: 151.86712646484375\r",
      "INFO - Step 4162, rl-loss: 211.05233764648438\r",
      "INFO - Step 4163, rl-loss: 242.30633544921875\r",
      "INFO - Step 4164, rl-loss: 70.34571838378906\r",
      "INFO - Step 4165, rl-loss: 135.03492736816406\r",
      "INFO - Step 4166, rl-loss: 216.1425323486328\r",
      "INFO - Step 4167, rl-loss: 326.3891906738281\r",
      "INFO - Step 4168, rl-loss: 300.8960266113281\r",
      "INFO - Step 4169, rl-loss: 54.86982727050781\r",
      "INFO - Step 4170, rl-loss: 51.22441101074219\r",
      "INFO - Step 4171, rl-loss: 97.07687377929688\r",
      "INFO - Step 4172, rl-loss: 80.66910552978516\r",
      "INFO - Step 4173, rl-loss: 229.35610961914062\r",
      "INFO - Step 4174, rl-loss: 186.84783935546875\r",
      "INFO - Step 4175, rl-loss: 343.45391845703125\r",
      "INFO - Step 4176, rl-loss: 203.40431213378906\r",
      "INFO - Step 4177, rl-loss: 60.41791534423828\r",
      "INFO - Step 4178, rl-loss: 254.25424194335938\r",
      "INFO - Step 4179, rl-loss: 62.21384811401367\r",
      "INFO - Step 4180, rl-loss: 88.94764709472656\r",
      "INFO - Step 4181, rl-loss: 111.39959716796875\r",
      "INFO - Step 4182, rl-loss: 96.03945922851562\r",
      "INFO - Step 4183, rl-loss: 325.4527893066406\r",
      "INFO - Step 4184, rl-loss: 350.038330078125\r",
      "INFO - Step 4185, rl-loss: 34.78365707397461\r",
      "INFO - Step 4186, rl-loss: 84.4412841796875\r",
      "INFO - Step 4187, rl-loss: 268.3627014160156\r",
      "INFO - Step 4188, rl-loss: 135.08831787109375\r",
      "INFO - Step 4189, rl-loss: 68.76679992675781\r",
      "INFO - Step 4190, rl-loss: 306.7052001953125\r",
      "INFO - Step 4191, rl-loss: 38.039695739746094\r",
      "INFO - Step 4192, rl-loss: 422.31817626953125\r",
      "INFO - Step 4193, rl-loss: 182.17811584472656\r",
      "INFO - Step 4194, rl-loss: 239.2567138671875\r",
      "INFO - Step 4195, rl-loss: 42.204315185546875\r",
      "INFO - Step 4196, rl-loss: 70.12356567382812\r",
      "INFO - Step 4197, rl-loss: 147.0554962158203\r",
      "INFO - Step 4198, rl-loss: 191.5917510986328\r",
      "INFO - Step 4199, rl-loss: 200.05535888671875\r",
      "INFO - Step 4200, rl-loss: 194.18043518066406\r",
      "INFO - Step 4201, rl-loss: 79.3878173828125\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4202, rl-loss: 125.31643676757812\r",
      "INFO - Step 4203, rl-loss: 57.07539367675781\r",
      "INFO - Step 4204, rl-loss: 244.81143188476562\r",
      "INFO - Step 4205, rl-loss: 84.56878662109375\r",
      "INFO - Step 4206, rl-loss: 441.452880859375\r",
      "INFO - Step 4207, rl-loss: 286.6702575683594\r",
      "INFO - Step 4208, rl-loss: 242.17959594726562\r",
      "INFO - Step 4209, rl-loss: 93.11564636230469\r",
      "INFO - Step 4210, rl-loss: 97.44972229003906\r",
      "INFO - Step 4211, rl-loss: 219.91802978515625\r",
      "INFO - Step 4212, rl-loss: 190.97598266601562\r",
      "INFO - Step 4213, rl-loss: 318.6362609863281\r",
      "INFO - Step 4214, rl-loss: 353.1095886230469\r",
      "INFO - Step 4215, rl-loss: 89.6120834350586\r",
      "INFO - Step 4216, rl-loss: 255.14613342285156\r",
      "INFO - Step 4217, rl-loss: 222.19293212890625\r",
      "INFO - Step 4218, rl-loss: 192.62925720214844\r",
      "INFO - Step 4219, rl-loss: 225.9393310546875\r",
      "INFO - Step 4220, rl-loss: 81.09255981445312\r",
      "INFO - Step 4221, rl-loss: 76.69212341308594\r",
      "INFO - Step 4222, rl-loss: 97.19772338867188\r",
      "INFO - Step 4223, rl-loss: 68.97856140136719\r",
      "INFO - Step 4224, rl-loss: 402.1211853027344\r",
      "INFO - Step 4225, rl-loss: 82.0740737915039\r",
      "INFO - Step 4226, rl-loss: 53.54463195800781\r",
      "INFO - Step 4227, rl-loss: 258.307373046875\r",
      "INFO - Step 4228, rl-loss: 57.676265716552734\r",
      "INFO - Step 4229, rl-loss: 350.4269714355469\r",
      "INFO - Step 4230, rl-loss: 75.33027648925781\r",
      "INFO - Step 4231, rl-loss: 229.53717041015625\r",
      "INFO - Step 4232, rl-loss: 64.78009796142578\r",
      "INFO - Step 4233, rl-loss: 193.5634307861328\r",
      "INFO - Step 4234, rl-loss: 64.03302764892578\r",
      "INFO - Step 4235, rl-loss: 171.85934448242188\r",
      "INFO - Step 4236, rl-loss: 41.77302932739258\r",
      "INFO - Step 4237, rl-loss: 63.45998764038086\r",
      "INFO - Step 4238, rl-loss: 74.74342346191406\r",
      "INFO - Step 4239, rl-loss: 451.7037353515625\r",
      "INFO - Step 4240, rl-loss: 46.03357696533203\r",
      "INFO - Step 4241, rl-loss: 145.31103515625\r",
      "INFO - Step 4242, rl-loss: 75.43072509765625\r",
      "INFO - Step 4243, rl-loss: 171.96646118164062\r",
      "INFO - Step 4244, rl-loss: 192.37254333496094\r",
      "INFO - Step 4245, rl-loss: 366.07366943359375\r",
      "INFO - Step 4246, rl-loss: 43.368324279785156\r",
      "INFO - Step 4247, rl-loss: 103.62722778320312\r",
      "INFO - Step 4248, rl-loss: 133.93472290039062\r",
      "INFO - Step 4249, rl-loss: 290.45880126953125\r",
      "INFO - Step 4250, rl-loss: 57.95064926147461\r",
      "INFO - Step 4251, rl-loss: 195.40774536132812\r",
      "INFO - Step 4252, rl-loss: 335.1761474609375\r",
      "INFO - Step 4253, rl-loss: 187.3875274658203\r",
      "INFO - Step 4254, rl-loss: 73.3067855834961\r",
      "INFO - Step 4255, rl-loss: 42.11201095581055\r",
      "INFO - Step 4256, rl-loss: 202.70700073242188\r",
      "INFO - Step 4257, rl-loss: 410.3511047363281\r",
      "INFO - Step 4258, rl-loss: 46.61906433105469\r",
      "INFO - Step 4259, rl-loss: 54.227203369140625\r",
      "INFO - Step 4260, rl-loss: 128.96923828125\r",
      "INFO - Step 4261, rl-loss: 87.2194595336914\r",
      "INFO - Step 4262, rl-loss: 334.3516540527344\r",
      "INFO - Step 4263, rl-loss: 294.69580078125\r",
      "INFO - Step 4264, rl-loss: 76.25245666503906\r",
      "INFO - Step 4265, rl-loss: 75.35198211669922\r",
      "INFO - Step 4266, rl-loss: 64.37477111816406\r",
      "INFO - Step 4267, rl-loss: 72.85961151123047\r",
      "INFO - Step 4268, rl-loss: 218.0923614501953\r",
      "INFO - Step 4269, rl-loss: 208.66098022460938\r",
      "INFO - Step 4270, rl-loss: 293.765380859375\r",
      "INFO - Step 4271, rl-loss: 202.46151733398438\r",
      "INFO - Step 4272, rl-loss: 66.68016052246094\r",
      "INFO - Step 4273, rl-loss: 169.30941772460938\r",
      "INFO - Step 4274, rl-loss: 119.8295669555664\r",
      "INFO - Step 4275, rl-loss: 48.488624572753906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 59/25000 [00:06<47:28,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 4276, rl-loss: 80.21424865722656\r",
      "INFO - Step 4277, rl-loss: 71.73915100097656\r",
      "INFO - Step 4278, rl-loss: 229.62905883789062\r",
      "INFO - Step 4279, rl-loss: 203.63917541503906\r",
      "INFO - Step 4280, rl-loss: 323.7493896484375\r",
      "INFO - Step 4281, rl-loss: 45.93803787231445\r",
      "INFO - Step 4282, rl-loss: 213.17881774902344\r",
      "INFO - Step 4283, rl-loss: 294.61993408203125\r",
      "INFO - Step 4284, rl-loss: 64.99214935302734\r",
      "INFO - Step 4285, rl-loss: 390.40625\r",
      "INFO - Step 4286, rl-loss: 60.45489501953125\r",
      "INFO - Step 4287, rl-loss: 730.6761474609375\r",
      "INFO - Step 4288, rl-loss: 155.55136108398438\r",
      "INFO - Step 4289, rl-loss: 159.47398376464844\r",
      "INFO - Step 4290, rl-loss: 203.5487060546875\r",
      "INFO - Step 4291, rl-loss: 193.65797424316406\r",
      "INFO - Step 4292, rl-loss: 67.71263122558594\r",
      "INFO - Step 4293, rl-loss: 88.90097045898438\r",
      "INFO - Step 4294, rl-loss: 313.88275146484375\r",
      "INFO - Step 4295, rl-loss: 85.83805847167969\r",
      "INFO - Step 4296, rl-loss: 148.26329040527344\r",
      "INFO - Step 4297, rl-loss: 110.6671142578125\r",
      "INFO - Step 4298, rl-loss: 230.7639923095703\r",
      "INFO - Step 4299, rl-loss: 246.54974365234375\r",
      "INFO - Step 4300, rl-loss: 216.16683959960938\r",
      "INFO - Step 4301, rl-loss: 52.87760925292969\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4302, rl-loss: 455.56231689453125\r",
      "INFO - Step 4303, rl-loss: 94.17253875732422\r",
      "INFO - Step 4304, rl-loss: 436.81732177734375\r",
      "INFO - Step 4305, rl-loss: 273.12872314453125\r",
      "INFO - Step 4306, rl-loss: 89.61178588867188\r",
      "INFO - Step 4307, rl-loss: 77.00022888183594\r",
      "INFO - Step 4308, rl-loss: 40.73302459716797\r",
      "INFO - Step 4309, rl-loss: 42.178611755371094\r",
      "INFO - Step 4310, rl-loss: 194.59588623046875\r",
      "INFO - Step 4311, rl-loss: 75.16085815429688\r",
      "INFO - Step 4312, rl-loss: 237.37200927734375\r",
      "INFO - Step 4313, rl-loss: 114.16126251220703\r",
      "INFO - Step 4314, rl-loss: 52.35201644897461\r",
      "INFO - Step 4315, rl-loss: 106.75939178466797\r",
      "INFO - Step 4316, rl-loss: 81.8357925415039\r",
      "INFO - Step 4317, rl-loss: 75.93295288085938\r",
      "INFO - Step 4318, rl-loss: 150.9591827392578\r",
      "INFO - Step 4319, rl-loss: 48.195396423339844\r",
      "INFO - Step 4320, rl-loss: 63.58208465576172\r",
      "INFO - Step 4321, rl-loss: 111.74207305908203\r",
      "INFO - Step 4322, rl-loss: 129.4091796875\r",
      "INFO - Step 4323, rl-loss: 136.99896240234375\r",
      "INFO - Step 4324, rl-loss: 176.03936767578125\r",
      "INFO - Step 4325, rl-loss: 406.22052001953125\r",
      "INFO - Step 4326, rl-loss: 151.33782958984375\r",
      "INFO - Step 4327, rl-loss: 99.00044250488281\r",
      "INFO - Step 4328, rl-loss: 365.7870178222656\r",
      "INFO - Step 4329, rl-loss: 179.39720153808594\r",
      "INFO - Step 4330, rl-loss: 160.7216339111328\r",
      "INFO - Step 4331, rl-loss: 49.73070526123047\r",
      "INFO - Step 4332, rl-loss: 344.925537109375\r",
      "INFO - Step 4333, rl-loss: 46.28486633300781\r",
      "INFO - Step 4334, rl-loss: 56.75391387939453\r",
      "INFO - Step 4335, rl-loss: 293.99810791015625\r",
      "INFO - Step 4336, rl-loss: 247.87733459472656\r",
      "INFO - Step 4337, rl-loss: 174.33290100097656\r",
      "INFO - Step 4338, rl-loss: 105.17706298828125\r",
      "INFO - Step 4339, rl-loss: 445.53155517578125\r",
      "INFO - Step 4340, rl-loss: 73.21912384033203\r",
      "INFO - Step 4341, rl-loss: 56.01976776123047\r",
      "INFO - Step 4342, rl-loss: 59.24359893798828\r",
      "INFO - Step 4343, rl-loss: 352.7315979003906\r",
      "INFO - Step 4344, rl-loss: 228.9417724609375\r",
      "INFO - Step 4345, rl-loss: 64.38985443115234\r",
      "INFO - Step 4346, rl-loss: 71.3812255859375\r",
      "INFO - Step 4347, rl-loss: 91.7122802734375\r",
      "INFO - Step 4348, rl-loss: 223.09503173828125\r",
      "INFO - Step 4349, rl-loss: 60.77996826171875\r",
      "INFO - Step 4350, rl-loss: 257.79937744140625\r",
      "INFO - Step 4351, rl-loss: 47.75440216064453\r",
      "INFO - Step 4352, rl-loss: 419.43194580078125\r",
      "INFO - Step 4353, rl-loss: 133.9774932861328\r",
      "INFO - Step 4354, rl-loss: 71.90457153320312\r",
      "INFO - Step 4355, rl-loss: 343.31085205078125\r",
      "INFO - Step 4356, rl-loss: 362.9082336425781\r",
      "INFO - Step 4357, rl-loss: 103.80889892578125\r",
      "INFO - Step 4358, rl-loss: 75.34629821777344\r",
      "INFO - Step 4359, rl-loss: 190.20590209960938\r",
      "INFO - Step 4360, rl-loss: 162.8527069091797\r",
      "INFO - Step 4361, rl-loss: 186.16464233398438\r",
      "INFO - Step 4362, rl-loss: 170.77716064453125\r",
      "INFO - Step 4363, rl-loss: 53.589805603027344\r",
      "INFO - Step 4364, rl-loss: 243.56515502929688\r",
      "INFO - Step 4365, rl-loss: 280.68634033203125\r",
      "INFO - Step 4366, rl-loss: 353.4902038574219\r",
      "INFO - Step 4367, rl-loss: 252.54165649414062\r",
      "INFO - Step 4368, rl-loss: 120.3926010131836\r",
      "INFO - Step 4369, rl-loss: 53.693634033203125\r",
      "INFO - Step 4370, rl-loss: 169.04534912109375\r",
      "INFO - Step 4371, rl-loss: 180.5986328125\r",
      "INFO - Step 4372, rl-loss: 369.50164794921875\r",
      "INFO - Step 4373, rl-loss: 198.32752990722656\r",
      "INFO - Step 4374, rl-loss: 373.0580749511719\r",
      "INFO - Step 4375, rl-loss: 191.86944580078125\r",
      "INFO - Step 4376, rl-loss: 381.1996154785156\r",
      "INFO - Step 4377, rl-loss: 103.40447998046875\r",
      "INFO - Step 4378, rl-loss: 220.59768676757812\r",
      "INFO - Step 4379, rl-loss: 64.52357482910156\r",
      "INFO - Step 4380, rl-loss: 244.7489013671875\r",
      "INFO - Step 4381, rl-loss: 82.36499786376953\r",
      "INFO - Step 4382, rl-loss: 92.0251235961914\r",
      "INFO - Step 4383, rl-loss: 177.3080596923828\r",
      "INFO - Step 4384, rl-loss: 64.18126678466797\r",
      "INFO - Step 4385, rl-loss: 73.85578918457031\r",
      "INFO - Step 4386, rl-loss: 81.48518371582031\r",
      "INFO - Step 4387, rl-loss: 69.4564208984375\r",
      "INFO - Step 4388, rl-loss: 202.16458129882812\r",
      "INFO - Step 4389, rl-loss: 36.69464111328125\r",
      "INFO - Step 4390, rl-loss: 391.77044677734375\r",
      "INFO - Step 4391, rl-loss: 186.70712280273438\r",
      "INFO - Step 4392, rl-loss: 277.46697998046875\r",
      "INFO - Step 4393, rl-loss: 91.89364624023438\r",
      "INFO - Step 4394, rl-loss: 203.3515167236328\r",
      "INFO - Step 4395, rl-loss: 80.56017303466797\r",
      "INFO - Step 4396, rl-loss: 131.386474609375\r",
      "INFO - Step 4397, rl-loss: 75.03982543945312\r",
      "INFO - Step 4398, rl-loss: 71.25787353515625\r",
      "INFO - Step 4399, rl-loss: 160.36227416992188\r",
      "INFO - Step 4400, rl-loss: 206.92227172851562\r",
      "INFO - Step 4401, rl-loss: 81.49286651611328\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4402, rl-loss: 77.9291000366211\r",
      "INFO - Step 4403, rl-loss: 285.7662048339844\r",
      "INFO - Step 4404, rl-loss: 36.36229705810547\r",
      "INFO - Step 4405, rl-loss: 102.00923156738281\r",
      "INFO - Step 4406, rl-loss: 118.40434265136719\r",
      "INFO - Step 4407, rl-loss: 269.5481872558594\r",
      "INFO - Step 4408, rl-loss: 96.15922546386719\r",
      "INFO - Step 4409, rl-loss: 147.46218872070312\r",
      "INFO - Step 4410, rl-loss: 169.35623168945312\r",
      "INFO - Step 4411, rl-loss: 36.572998046875\r",
      "INFO - Step 4412, rl-loss: 460.5106506347656\r",
      "INFO - Step 4413, rl-loss: 484.66131591796875\r",
      "INFO - Step 4414, rl-loss: 178.52752685546875\r",
      "INFO - Step 4415, rl-loss: 372.33465576171875\r",
      "INFO - Step 4416, rl-loss: 238.23635864257812\r",
      "INFO - Step 4417, rl-loss: 283.6070556640625\r",
      "INFO - Step 4418, rl-loss: 338.587158203125\r",
      "INFO - Step 4419, rl-loss: 325.6645202636719\r",
      "INFO - Step 4420, rl-loss: 79.13072967529297\r",
      "INFO - Step 4421, rl-loss: 240.38650512695312\r",
      "INFO - Step 4422, rl-loss: 95.3504638671875\r",
      "INFO - Step 4423, rl-loss: 342.22393798828125\r",
      "INFO - Step 4424, rl-loss: 262.0338439941406\r",
      "INFO - Step 4425, rl-loss: 94.35828399658203\r",
      "INFO - Step 4426, rl-loss: 212.1866455078125\r",
      "INFO - Step 4427, rl-loss: 164.44618225097656\r",
      "INFO - Step 4428, rl-loss: 55.981956481933594\r",
      "INFO - Step 4429, rl-loss: 146.9535675048828\r",
      "INFO - Step 4430, rl-loss: 153.81776428222656\r",
      "INFO - Step 4431, rl-loss: 166.63616943359375\r",
      "INFO - Step 4432, rl-loss: 329.4154052734375\r",
      "INFO - Step 4433, rl-loss: 91.66482543945312\r",
      "INFO - Step 4434, rl-loss: 164.99325561523438\r",
      "INFO - Step 4435, rl-loss: 202.31646728515625\r",
      "INFO - Step 4436, rl-loss: 241.69679260253906\r",
      "INFO - Step 4437, rl-loss: 165.8727569580078\r",
      "INFO - Step 4438, rl-loss: 99.34513854980469\r",
      "INFO - Step 4439, rl-loss: 221.3119659423828\r",
      "INFO - Step 4440, rl-loss: 90.51506042480469\r",
      "INFO - Step 4441, rl-loss: 189.74713134765625\r",
      "INFO - Step 4442, rl-loss: 161.41932678222656\r",
      "INFO - Step 4443, rl-loss: 98.96466064453125\r",
      "INFO - Step 4444, rl-loss: 185.71018981933594\r",
      "INFO - Step 4445, rl-loss: 56.758056640625\r",
      "INFO - Step 4446, rl-loss: 411.32427978515625\r",
      "INFO - Step 4447, rl-loss: 83.6093521118164\r",
      "INFO - Step 4448, rl-loss: 67.12307739257812\r",
      "INFO - Step 4449, rl-loss: 240.50521850585938\r",
      "INFO - Step 4450, rl-loss: 82.33946228027344\r",
      "INFO - Step 4451, rl-loss: 48.11029815673828\r",
      "INFO - Step 4452, rl-loss: 60.16386032104492\r",
      "INFO - Step 4453, rl-loss: 262.69091796875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 67/25000 [00:07<45:02,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 4454, rl-loss: 59.931549072265625\r",
      "INFO - Step 4455, rl-loss: 61.516380310058594\r",
      "INFO - Step 4456, rl-loss: 80.7306900024414\r",
      "INFO - Step 4457, rl-loss: 392.0959167480469\r",
      "INFO - Step 4458, rl-loss: 55.77306365966797\r",
      "INFO - Step 4459, rl-loss: 315.9853210449219\r",
      "INFO - Step 4460, rl-loss: 198.34873962402344\r",
      "INFO - Step 4461, rl-loss: 112.45957946777344\r",
      "INFO - Step 4462, rl-loss: 104.45378112792969\r",
      "INFO - Step 4463, rl-loss: 75.99278259277344\r",
      "INFO - Step 4464, rl-loss: 232.22396850585938\r",
      "INFO - Step 4465, rl-loss: 120.391845703125\r",
      "INFO - Step 4466, rl-loss: 229.51394653320312\r",
      "INFO - Step 4467, rl-loss: 103.97528839111328\r",
      "INFO - Step 4468, rl-loss: 54.652748107910156\r",
      "INFO - Step 4469, rl-loss: 119.28065490722656\r",
      "INFO - Step 4470, rl-loss: 219.73338317871094\r",
      "INFO - Step 4471, rl-loss: 56.620750427246094\r",
      "INFO - Step 4472, rl-loss: 186.1097412109375\r",
      "INFO - Step 4473, rl-loss: 153.61721801757812\r",
      "INFO - Step 4474, rl-loss: 173.6732177734375\r",
      "INFO - Step 4475, rl-loss: 191.79161071777344\r",
      "INFO - Step 4476, rl-loss: 59.59307098388672\r",
      "INFO - Step 4477, rl-loss: 399.7876892089844\r",
      "INFO - Step 4478, rl-loss: 89.72588348388672\r",
      "INFO - Step 4479, rl-loss: 273.5986633300781\r",
      "INFO - Step 4480, rl-loss: 164.7823028564453\r",
      "INFO - Step 4481, rl-loss: 219.6004638671875\r",
      "INFO - Step 4482, rl-loss: 208.5062255859375\r",
      "INFO - Step 4483, rl-loss: 95.86164093017578\r",
      "INFO - Step 4484, rl-loss: 210.0466766357422\r",
      "INFO - Step 4485, rl-loss: 94.62155151367188\r",
      "INFO - Step 4486, rl-loss: 211.67529296875\r",
      "INFO - Step 4487, rl-loss: 67.41814422607422\r",
      "INFO - Step 4488, rl-loss: 202.4285430908203\r",
      "INFO - Step 4489, rl-loss: 146.99215698242188\r",
      "INFO - Step 4490, rl-loss: 233.61138916015625\r",
      "INFO - Step 4491, rl-loss: 234.244384765625\r",
      "INFO - Step 4492, rl-loss: 128.45469665527344\r",
      "INFO - Step 4493, rl-loss: 42.21666717529297\r",
      "INFO - Step 4494, rl-loss: 233.6476593017578\r",
      "INFO - Step 4495, rl-loss: 51.480072021484375\r",
      "INFO - Step 4496, rl-loss: 379.5225830078125\r",
      "INFO - Step 4497, rl-loss: 276.47222900390625\r",
      "INFO - Step 4498, rl-loss: 342.0758056640625\r",
      "INFO - Step 4499, rl-loss: 66.65530395507812\r",
      "INFO - Step 4500, rl-loss: 138.40060424804688\r",
      "INFO - Step 4501, rl-loss: 447.5536193847656\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4502, rl-loss: 36.94698715209961\r",
      "INFO - Step 4503, rl-loss: 348.56597900390625\r",
      "INFO - Step 4504, rl-loss: 176.50558471679688\r",
      "INFO - Step 4505, rl-loss: 132.78616333007812\r",
      "INFO - Step 4506, rl-loss: 274.07952880859375\r",
      "INFO - Step 4507, rl-loss: 95.69851684570312\r",
      "INFO - Step 4508, rl-loss: 419.55902099609375\r",
      "INFO - Step 4509, rl-loss: 98.02037048339844\r",
      "INFO - Step 4510, rl-loss: 148.7181396484375\r",
      "INFO - Step 4511, rl-loss: 190.8157501220703\r",
      "INFO - Step 4512, rl-loss: 182.99331665039062\r",
      "INFO - Step 4513, rl-loss: 199.05667114257812\r",
      "INFO - Step 4514, rl-loss: 221.05532836914062\r",
      "INFO - Step 4515, rl-loss: 105.4903564453125\r",
      "INFO - Step 4516, rl-loss: 48.80190658569336\r",
      "INFO - Step 4517, rl-loss: 89.47318267822266\r",
      "INFO - Step 4518, rl-loss: 61.63002014160156\r",
      "INFO - Step 4519, rl-loss: 49.72322082519531\r",
      "INFO - Step 4520, rl-loss: 101.30069732666016\r",
      "INFO - Step 4521, rl-loss: 307.4659118652344\r",
      "INFO - Step 4522, rl-loss: 93.96794128417969\r",
      "INFO - Step 4523, rl-loss: 74.12467193603516\r",
      "INFO - Step 4524, rl-loss: 201.50335693359375\r",
      "INFO - Step 4525, rl-loss: 70.06835174560547\r",
      "INFO - Step 4526, rl-loss: 43.044673919677734\r",
      "INFO - Step 4527, rl-loss: 268.42242431640625\r",
      "INFO - Step 4528, rl-loss: 279.4151306152344\r",
      "INFO - Step 4529, rl-loss: 36.769561767578125\r",
      "INFO - Step 4530, rl-loss: 113.033935546875\r",
      "INFO - Step 4531, rl-loss: 297.3940734863281\r",
      "INFO - Step 4532, rl-loss: 39.96915817260742\r",
      "INFO - Step 4533, rl-loss: 101.7203369140625\r",
      "INFO - Step 4534, rl-loss: 219.72659301757812\r",
      "INFO - Step 4535, rl-loss: 165.34915161132812\r",
      "INFO - Step 4536, rl-loss: 237.43405151367188\r",
      "INFO - Step 4537, rl-loss: 43.508052825927734\r",
      "INFO - Step 4538, rl-loss: 369.0616455078125\r",
      "INFO - Step 4539, rl-loss: 72.36205291748047\r",
      "INFO - Step 4540, rl-loss: 74.34906005859375\r",
      "INFO - Step 4541, rl-loss: 74.5653305053711\r",
      "INFO - Step 4542, rl-loss: 102.45397186279297\r",
      "INFO - Step 4543, rl-loss: 62.884056091308594\r",
      "INFO - Step 4544, rl-loss: 232.53369140625\r",
      "INFO - Step 4545, rl-loss: 230.7275848388672\r",
      "INFO - Step 4546, rl-loss: 46.97123718261719\r",
      "INFO - Step 4547, rl-loss: 258.226806640625\r",
      "INFO - Step 4548, rl-loss: 209.4375457763672\r",
      "INFO - Step 4549, rl-loss: 274.5633850097656\r",
      "INFO - Step 4550, rl-loss: 151.18653869628906\r",
      "INFO - Step 4551, rl-loss: 312.982421875\r",
      "INFO - Step 4552, rl-loss: 118.16625213623047\r",
      "INFO - Step 4553, rl-loss: 268.2080993652344\r",
      "INFO - Step 4554, rl-loss: 253.81002807617188\r",
      "INFO - Step 4555, rl-loss: 104.81723022460938\r",
      "INFO - Step 4556, rl-loss: 138.12167358398438\r",
      "INFO - Step 4557, rl-loss: 326.41766357421875\r",
      "INFO - Step 4558, rl-loss: 100.46189880371094\r",
      "INFO - Step 4559, rl-loss: 91.58958435058594\r",
      "INFO - Step 4560, rl-loss: 427.3523254394531\r",
      "INFO - Step 4561, rl-loss: 51.32196044921875\r",
      "INFO - Step 4562, rl-loss: 110.72808074951172\r",
      "INFO - Step 4563, rl-loss: 44.65773010253906\r",
      "INFO - Step 4564, rl-loss: 394.99462890625\r",
      "INFO - Step 4565, rl-loss: 286.0263671875\r",
      "INFO - Step 4566, rl-loss: 83.92225646972656\r",
      "INFO - Step 4567, rl-loss: 94.631591796875\r",
      "INFO - Step 4568, rl-loss: 440.3164978027344\r",
      "INFO - Step 4569, rl-loss: 221.16171264648438\r",
      "INFO - Step 4570, rl-loss: 95.23062133789062\r",
      "INFO - Step 4571, rl-loss: 72.01953125\r",
      "INFO - Step 4572, rl-loss: 135.5091094970703\r",
      "INFO - Step 4573, rl-loss: 475.78057861328125\r",
      "INFO - Step 4574, rl-loss: 177.66299438476562\r",
      "INFO - Step 4575, rl-loss: 217.27957153320312\r",
      "INFO - Step 4576, rl-loss: 285.4267272949219\r",
      "INFO - Step 4577, rl-loss: 72.9276351928711\r",
      "INFO - Step 4578, rl-loss: 178.03433227539062\r",
      "INFO - Step 4579, rl-loss: 365.30963134765625\r",
      "INFO - Step 4580, rl-loss: 340.58758544921875\r",
      "INFO - Step 4581, rl-loss: 83.15025329589844\r",
      "INFO - Step 4582, rl-loss: 311.28533935546875\r",
      "INFO - Step 4583, rl-loss: 114.86309051513672\r",
      "INFO - Step 4584, rl-loss: 108.8924560546875\r",
      "INFO - Step 4585, rl-loss: 291.5987548828125\r",
      "INFO - Step 4586, rl-loss: 104.98355102539062\r",
      "INFO - Step 4587, rl-loss: 245.11251831054688\r",
      "INFO - Step 4588, rl-loss: 160.53872680664062\r",
      "INFO - Step 4589, rl-loss: 82.96998596191406\r",
      "INFO - Step 4590, rl-loss: 101.16017150878906\r",
      "INFO - Step 4591, rl-loss: 304.604736328125\r",
      "INFO - Step 4592, rl-loss: 85.21635437011719\r",
      "INFO - Step 4593, rl-loss: 94.79395294189453\r",
      "INFO - Step 4594, rl-loss: 342.3888244628906\r",
      "INFO - Step 4595, rl-loss: 176.7320098876953\r",
      "INFO - Step 4596, rl-loss: 209.12911987304688\r",
      "INFO - Step 4597, rl-loss: 67.91519165039062\r",
      "INFO - Step 4598, rl-loss: 381.4681091308594\r",
      "INFO - Step 4599, rl-loss: 431.414794921875\r",
      "INFO - Step 4600, rl-loss: 95.57247924804688\r",
      "INFO - Step 4601, rl-loss: 66.02154541015625\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4602, rl-loss: 73.66136932373047\r",
      "INFO - Step 4603, rl-loss: 92.16132354736328\r",
      "INFO - Step 4604, rl-loss: 104.127197265625\r",
      "INFO - Step 4605, rl-loss: 68.05211639404297\r",
      "INFO - Step 4606, rl-loss: 175.12109375\r",
      "INFO - Step 4607, rl-loss: 77.00334167480469\r",
      "INFO - Step 4608, rl-loss: 365.1705017089844\r",
      "INFO - Step 4609, rl-loss: 190.86497497558594\r",
      "INFO - Step 4610, rl-loss: 331.6033630371094\r",
      "INFO - Step 4611, rl-loss: 236.3954315185547\r",
      "INFO - Step 4612, rl-loss: 223.01458740234375\r",
      "INFO - Step 4613, rl-loss: 199.53086853027344\r",
      "INFO - Step 4614, rl-loss: 31.509761810302734\r",
      "INFO - Step 4615, rl-loss: 60.82700729370117\r",
      "INFO - Step 4616, rl-loss: 200.98184204101562\r",
      "INFO - Step 4617, rl-loss: 57.272979736328125\r",
      "INFO - Step 4618, rl-loss: 62.92803955078125\r",
      "INFO - Step 4619, rl-loss: 51.016845703125\r",
      "INFO - Step 4620, rl-loss: 84.70857238769531\r",
      "INFO - Step 4621, rl-loss: 55.84756088256836\r",
      "INFO - Step 4622, rl-loss: 134.77774047851562\r",
      "INFO - Step 4623, rl-loss: 186.2659912109375\r",
      "INFO - Step 4624, rl-loss: 68.59414672851562\r",
      "INFO - Step 4625, rl-loss: 83.24555969238281\r",
      "INFO - Step 4626, rl-loss: 274.3800048828125\r",
      "INFO - Step 4627, rl-loss: 193.83543395996094\r",
      "INFO - Step 4628, rl-loss: 73.36898803710938\r",
      "INFO - Step 4629, rl-loss: 227.19639587402344\r",
      "INFO - Step 4630, rl-loss: 323.487548828125\r",
      "INFO - Step 4631, rl-loss: 182.5098876953125\r",
      "INFO - Step 4632, rl-loss: 78.7564468383789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 75/25000 [00:07<35:30, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 4633, rl-loss: 149.8221435546875\r",
      "INFO - Step 4634, rl-loss: 95.56571197509766\r",
      "INFO - Step 4635, rl-loss: 40.805912017822266\r",
      "INFO - Step 4636, rl-loss: 183.32635498046875\r",
      "INFO - Step 4637, rl-loss: 68.60238647460938\r",
      "INFO - Step 4638, rl-loss: 416.5442810058594\r",
      "INFO - Step 4639, rl-loss: 48.76774978637695\r",
      "INFO - Step 4640, rl-loss: 124.55915069580078\r",
      "INFO - Step 4641, rl-loss: 159.70924377441406\r",
      "INFO - Step 4642, rl-loss: 266.3915710449219\r",
      "INFO - Step 4643, rl-loss: 170.72177124023438\r",
      "INFO - Step 4644, rl-loss: 150.85836791992188\r",
      "INFO - Step 4645, rl-loss: 94.8963851928711\r",
      "INFO - Step 4646, rl-loss: 197.70713806152344\r",
      "INFO - Step 4647, rl-loss: 109.86631774902344\r",
      "INFO - Step 4648, rl-loss: 218.63478088378906\r",
      "INFO - Step 4649, rl-loss: 384.2030029296875\r",
      "INFO - Step 4650, rl-loss: 149.4080047607422\r",
      "INFO - Step 4651, rl-loss: 123.94218444824219\r",
      "INFO - Step 4652, rl-loss: 79.51454162597656\r",
      "INFO - Step 4653, rl-loss: 60.87617874145508\r",
      "INFO - Step 4654, rl-loss: 142.5921630859375\r",
      "INFO - Step 4655, rl-loss: 284.1402893066406\r",
      "INFO - Step 4656, rl-loss: 89.63969421386719\r",
      "INFO - Step 4657, rl-loss: 393.56866455078125\r",
      "INFO - Step 4658, rl-loss: 65.99392700195312\r",
      "INFO - Step 4659, rl-loss: 381.475830078125\r",
      "INFO - Step 4660, rl-loss: 150.51556396484375\r",
      "INFO - Step 4661, rl-loss: 342.95989990234375\r",
      "INFO - Step 4662, rl-loss: 275.2334289550781\r",
      "INFO - Step 4663, rl-loss: 128.1025848388672\r",
      "INFO - Step 4664, rl-loss: 80.98509216308594\r",
      "INFO - Step 4665, rl-loss: 114.09733581542969\r",
      "INFO - Step 4666, rl-loss: 265.80987548828125\r",
      "INFO - Step 4667, rl-loss: 71.86160278320312\r",
      "INFO - Step 4668, rl-loss: 80.51272583007812\r",
      "INFO - Step 4669, rl-loss: 51.132781982421875\r",
      "INFO - Step 4670, rl-loss: 201.56854248046875\r",
      "INFO - Step 4671, rl-loss: 93.46295166015625\r",
      "INFO - Step 4672, rl-loss: 151.1320037841797\r",
      "INFO - Step 4673, rl-loss: 66.64221954345703\r",
      "INFO - Step 4674, rl-loss: 180.66561889648438\r",
      "INFO - Step 4675, rl-loss: 264.49591064453125\r",
      "INFO - Step 4676, rl-loss: 70.48391723632812\r",
      "INFO - Step 4677, rl-loss: 84.50259399414062\r",
      "INFO - Step 4678, rl-loss: 95.61046600341797\r",
      "INFO - Step 4679, rl-loss: 213.8445281982422\r",
      "INFO - Step 4680, rl-loss: 183.38145446777344\r",
      "INFO - Step 4681, rl-loss: 86.42924499511719\r",
      "INFO - Step 4682, rl-loss: 443.880615234375\r",
      "INFO - Step 4683, rl-loss: 192.87686157226562\r",
      "INFO - Step 4684, rl-loss: 77.79666137695312\r",
      "INFO - Step 4685, rl-loss: 199.08534240722656\r",
      "INFO - Step 4686, rl-loss: 80.43705749511719\r",
      "INFO - Step 4687, rl-loss: 74.91065979003906\r",
      "INFO - Step 4688, rl-loss: 84.43876647949219\r",
      "INFO - Step 4689, rl-loss: 44.27006912231445\r",
      "INFO - Step 4690, rl-loss: 134.0601806640625\r",
      "INFO - Step 4691, rl-loss: 101.81964111328125\r",
      "INFO - Step 4692, rl-loss: 53.7501335144043\r",
      "INFO - Step 4693, rl-loss: 64.4830322265625\r",
      "INFO - Step 4694, rl-loss: 263.27996826171875\r",
      "INFO - Step 4695, rl-loss: 91.74287414550781\r",
      "INFO - Step 4696, rl-loss: 246.1151885986328\r",
      "INFO - Step 4697, rl-loss: 257.8152160644531\r",
      "INFO - Step 4698, rl-loss: 79.90082550048828\r",
      "INFO - Step 4699, rl-loss: 231.93397521972656\r",
      "INFO - Step 4700, rl-loss: 151.79226684570312\r",
      "INFO - Step 4701, rl-loss: 113.5064697265625\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4702, rl-loss: 72.12387084960938\r",
      "INFO - Step 4703, rl-loss: 79.33491516113281\r",
      "INFO - Step 4704, rl-loss: 200.19943237304688\r",
      "INFO - Step 4705, rl-loss: 161.91925048828125\r",
      "INFO - Step 4706, rl-loss: 93.91743469238281\r",
      "INFO - Step 4707, rl-loss: 143.67828369140625\r",
      "INFO - Step 4708, rl-loss: 230.90350341796875\r",
      "INFO - Step 4709, rl-loss: 104.55308532714844\r",
      "INFO - Step 4710, rl-loss: 148.3501739501953\r",
      "INFO - Step 4711, rl-loss: 59.06360626220703\r",
      "INFO - Step 4712, rl-loss: 136.865478515625\r",
      "INFO - Step 4713, rl-loss: 293.66326904296875\r",
      "INFO - Step 4714, rl-loss: 123.50321960449219\r",
      "INFO - Step 4715, rl-loss: 181.67987060546875\r",
      "INFO - Step 4716, rl-loss: 475.6774597167969\r",
      "INFO - Step 4717, rl-loss: 181.15176391601562\r",
      "INFO - Step 4718, rl-loss: 74.22660827636719\r",
      "INFO - Step 4719, rl-loss: 94.34181213378906\r",
      "INFO - Step 4720, rl-loss: 43.03794860839844\r",
      "INFO - Step 4721, rl-loss: 310.49493408203125\r",
      "INFO - Step 4722, rl-loss: 73.20726013183594\r",
      "INFO - Step 4723, rl-loss: 52.78786849975586\r",
      "INFO - Step 4724, rl-loss: 53.863616943359375\r",
      "INFO - Step 4725, rl-loss: 375.24249267578125\r",
      "INFO - Step 4726, rl-loss: 301.554931640625\r",
      "INFO - Step 4727, rl-loss: 80.18290710449219\r",
      "INFO - Step 4728, rl-loss: 123.16603088378906\r",
      "INFO - Step 4729, rl-loss: 248.91348266601562\r",
      "INFO - Step 4730, rl-loss: 202.96205139160156\r",
      "INFO - Step 4731, rl-loss: 210.25755310058594\r",
      "INFO - Step 4732, rl-loss: 163.43218994140625\r",
      "INFO - Step 4733, rl-loss: 543.193359375\r",
      "INFO - Step 4734, rl-loss: 213.8050994873047\r",
      "INFO - Step 4735, rl-loss: 110.83760070800781\r",
      "INFO - Step 4736, rl-loss: 165.2792510986328\r",
      "INFO - Step 4737, rl-loss: 65.05611419677734\r",
      "INFO - Step 4738, rl-loss: 311.0760498046875\r",
      "INFO - Step 4739, rl-loss: 352.2625427246094\r",
      "INFO - Step 4740, rl-loss: 236.62965393066406\r",
      "INFO - Step 4741, rl-loss: 64.73451232910156\r",
      "INFO - Step 4742, rl-loss: 309.06744384765625\r",
      "INFO - Step 4743, rl-loss: 292.5466613769531\r",
      "INFO - Step 4744, rl-loss: 204.88629150390625\r",
      "INFO - Step 4745, rl-loss: 127.95721435546875\r",
      "INFO - Step 4746, rl-loss: 121.29633331298828\r",
      "INFO - Step 4747, rl-loss: 63.55776596069336\r",
      "INFO - Step 4748, rl-loss: 348.8950500488281\r",
      "INFO - Step 4749, rl-loss: 281.8182373046875\r",
      "INFO - Step 4750, rl-loss: 83.13679504394531\r",
      "INFO - Step 4751, rl-loss: 160.36178588867188\r",
      "INFO - Step 4752, rl-loss: 89.82368469238281\r",
      "INFO - Step 4753, rl-loss: 209.83551025390625\r",
      "INFO - Step 4754, rl-loss: 196.8389129638672\r",
      "INFO - Step 4755, rl-loss: 82.13789367675781\r",
      "INFO - Step 4756, rl-loss: 92.47242736816406\r",
      "INFO - Step 4757, rl-loss: 161.24859619140625\r",
      "INFO - Step 4758, rl-loss: 294.7237548828125\r",
      "INFO - Step 4759, rl-loss: 276.5384216308594\r",
      "INFO - Step 4760, rl-loss: 121.85719299316406\r",
      "INFO - Step 4761, rl-loss: 85.5059814453125\r",
      "INFO - Step 4762, rl-loss: 187.6973876953125\r",
      "INFO - Step 4763, rl-loss: 198.91566467285156\r",
      "INFO - Step 4764, rl-loss: 81.84306335449219\r",
      "INFO - Step 4765, rl-loss: 102.43161010742188\r",
      "INFO - Step 4766, rl-loss: 278.59844970703125\r",
      "INFO - Step 4767, rl-loss: 159.73037719726562\r",
      "INFO - Step 4768, rl-loss: 257.618896484375\r",
      "INFO - Step 4769, rl-loss: 111.85736083984375\r",
      "INFO - Step 4770, rl-loss: 153.3172607421875\r",
      "INFO - Step 4771, rl-loss: 277.3000793457031\r",
      "INFO - Step 4772, rl-loss: 109.23517608642578\r",
      "INFO - Step 4773, rl-loss: 149.7159423828125\r",
      "INFO - Step 4774, rl-loss: 245.64749145507812\r",
      "INFO - Step 4775, rl-loss: 67.27595520019531\r",
      "INFO - Step 4776, rl-loss: 65.6643295288086\r",
      "INFO - Step 4777, rl-loss: 80.76834106445312\r",
      "INFO - Step 4778, rl-loss: 341.50299072265625\r",
      "INFO - Step 4779, rl-loss: 423.96429443359375\r",
      "INFO - Step 4780, rl-loss: 153.6177215576172\r",
      "INFO - Step 4781, rl-loss: 148.71852111816406\r",
      "INFO - Step 4782, rl-loss: 172.12420654296875\r",
      "INFO - Step 4783, rl-loss: 216.2777099609375\r",
      "INFO - Step 4784, rl-loss: 301.9064025878906\r",
      "INFO - Step 4785, rl-loss: 148.37440490722656\r",
      "INFO - Step 4786, rl-loss: 105.92588806152344\r",
      "INFO - Step 4787, rl-loss: 98.49298095703125\r",
      "INFO - Step 4788, rl-loss: 276.9258728027344\r",
      "INFO - Step 4789, rl-loss: 139.29714965820312\r",
      "INFO - Step 4790, rl-loss: 290.3410339355469\r",
      "INFO - Step 4791, rl-loss: 121.80801391601562\r",
      "INFO - Step 4792, rl-loss: 414.8028564453125\r",
      "INFO - Step 4793, rl-loss: 53.04520797729492\r",
      "INFO - Step 4794, rl-loss: 84.4036865234375\r",
      "INFO - Step 4795, rl-loss: 139.9414825439453\r",
      "INFO - Step 4796, rl-loss: 236.5491943359375\r",
      "INFO - Step 4797, rl-loss: 240.4855499267578\r",
      "INFO - Step 4798, rl-loss: 145.00167846679688\r",
      "INFO - Step 4799, rl-loss: 46.34635925292969\r",
      "INFO - Step 4800, rl-loss: 44.9644775390625\r",
      "INFO - Step 4801, rl-loss: 59.19429016113281\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4802, rl-loss: 51.382843017578125\r",
      "INFO - Step 4803, rl-loss: 285.3995056152344\r",
      "INFO - Step 4804, rl-loss: 124.24510192871094\r",
      "INFO - Step 4805, rl-loss: 187.7559051513672\r",
      "INFO - Step 4806, rl-loss: 44.523956298828125\r",
      "INFO - Step 4807, rl-loss: 289.33502197265625\r",
      "INFO - Step 4808, rl-loss: 182.47633361816406\r",
      "INFO - Step 4809, rl-loss: 274.897216796875\r",
      "INFO - Step 4810, rl-loss: 216.84536743164062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 85/25000 [00:08<32:15, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 4811, rl-loss: 177.8228759765625\r",
      "INFO - Step 4812, rl-loss: 296.6627197265625\r",
      "INFO - Step 4813, rl-loss: 65.25407409667969\r",
      "INFO - Step 4814, rl-loss: 330.288818359375\r",
      "INFO - Step 4815, rl-loss: 224.4496307373047\r",
      "INFO - Step 4816, rl-loss: 200.29391479492188\r",
      "INFO - Step 4817, rl-loss: 120.21029663085938\r",
      "INFO - Step 4818, rl-loss: 180.4665985107422\r",
      "INFO - Step 4819, rl-loss: 152.17352294921875\r",
      "INFO - Step 4820, rl-loss: 99.72206115722656\r",
      "INFO - Step 4821, rl-loss: 80.2011489868164\r",
      "INFO - Step 4822, rl-loss: 121.78144836425781\r",
      "INFO - Step 4823, rl-loss: 139.41073608398438\r",
      "INFO - Step 4824, rl-loss: 142.8125\r",
      "INFO - Step 4825, rl-loss: 227.80052185058594\r",
      "INFO - Step 4826, rl-loss: 116.33967590332031\r",
      "INFO - Step 4827, rl-loss: 213.6270751953125\r",
      "INFO - Step 4828, rl-loss: 85.21214294433594\r",
      "INFO - Step 4829, rl-loss: 333.4465026855469\r",
      "INFO - Step 4830, rl-loss: 49.15685272216797\r",
      "INFO - Step 4831, rl-loss: 184.74838256835938\r",
      "INFO - Step 4832, rl-loss: 115.18624877929688\r",
      "INFO - Step 4833, rl-loss: 69.12052917480469\r",
      "INFO - Step 4834, rl-loss: 105.141357421875\r",
      "INFO - Step 4835, rl-loss: 176.50009155273438\r",
      "INFO - Step 4836, rl-loss: 63.12801742553711\r",
      "INFO - Step 4837, rl-loss: 134.41659545898438\r",
      "INFO - Step 4838, rl-loss: 245.2497100830078\r",
      "INFO - Step 4839, rl-loss: 248.24839782714844\r",
      "INFO - Step 4840, rl-loss: 288.0968933105469\r",
      "INFO - Step 4841, rl-loss: 110.79658508300781\r",
      "INFO - Step 4842, rl-loss: 319.4543151855469\r",
      "INFO - Step 4843, rl-loss: 118.2716064453125\r",
      "INFO - Step 4844, rl-loss: 63.79002380371094\r",
      "INFO - Step 4845, rl-loss: 42.74835205078125\r",
      "INFO - Step 4846, rl-loss: 374.65960693359375\r",
      "INFO - Step 4847, rl-loss: 134.56402587890625\r",
      "INFO - Step 4848, rl-loss: 417.2406921386719\r",
      "INFO - Step 4849, rl-loss: 305.88018798828125\r",
      "INFO - Step 4850, rl-loss: 137.34701538085938\r",
      "INFO - Step 4851, rl-loss: 216.42047119140625\r",
      "INFO - Step 4852, rl-loss: 297.8477783203125\r",
      "INFO - Step 4853, rl-loss: 148.09912109375\r",
      "INFO - Step 4854, rl-loss: 70.96112823486328\r",
      "INFO - Step 4855, rl-loss: 207.02243041992188\r",
      "INFO - Step 4856, rl-loss: 236.24868774414062\r",
      "INFO - Step 4857, rl-loss: 57.156463623046875\r",
      "INFO - Step 4858, rl-loss: 92.04307556152344\r",
      "INFO - Step 4859, rl-loss: 116.61325073242188\r",
      "INFO - Step 4860, rl-loss: 249.3927001953125\r",
      "INFO - Step 4861, rl-loss: 432.7184753417969\r",
      "INFO - Step 4862, rl-loss: 176.98895263671875\r",
      "INFO - Step 4863, rl-loss: 141.764892578125\r",
      "INFO - Step 4864, rl-loss: 208.703125\r",
      "INFO - Step 4865, rl-loss: 259.0052490234375\r",
      "INFO - Step 4866, rl-loss: 51.04859161376953\r",
      "INFO - Step 4867, rl-loss: 83.00508117675781\r",
      "INFO - Step 4868, rl-loss: 71.42584228515625\r",
      "INFO - Step 4869, rl-loss: 524.9226684570312\r",
      "INFO - Step 4870, rl-loss: 313.1909484863281\r",
      "INFO - Step 4871, rl-loss: 300.2967529296875\r",
      "INFO - Step 4872, rl-loss: 354.3634033203125\r",
      "INFO - Step 4873, rl-loss: 77.67958068847656\r",
      "INFO - Step 4874, rl-loss: 97.18408203125\r",
      "INFO - Step 4875, rl-loss: 199.80477905273438\r",
      "INFO - Step 4876, rl-loss: 143.2186279296875\r",
      "INFO - Step 4877, rl-loss: 65.97784423828125\r",
      "INFO - Step 4878, rl-loss: 56.53810119628906\r",
      "INFO - Step 4879, rl-loss: 150.12962341308594\r",
      "INFO - Step 4880, rl-loss: 228.1158447265625\r",
      "INFO - Step 4881, rl-loss: 362.1474609375\r",
      "INFO - Step 4882, rl-loss: 424.68499755859375\r",
      "INFO - Step 4883, rl-loss: 179.86636352539062\r",
      "INFO - Step 4884, rl-loss: 428.9906311035156\r",
      "INFO - Step 4885, rl-loss: 159.95184326171875\r",
      "INFO - Step 4886, rl-loss: 565.1238403320312\r",
      "INFO - Step 4887, rl-loss: 109.29109954833984\r",
      "INFO - Step 4888, rl-loss: 63.38063049316406\r",
      "INFO - Step 4889, rl-loss: 103.78482055664062\r",
      "INFO - Step 4890, rl-loss: 219.80865478515625\r",
      "INFO - Step 4891, rl-loss: 147.0193634033203\r",
      "INFO - Step 4892, rl-loss: 357.94677734375\r",
      "INFO - Step 4893, rl-loss: 190.5686798095703\r",
      "INFO - Step 4894, rl-loss: 174.1057891845703\r",
      "INFO - Step 4895, rl-loss: 102.42436218261719\r",
      "INFO - Step 4896, rl-loss: 205.82630920410156\r",
      "INFO - Step 4897, rl-loss: 425.45599365234375\r",
      "INFO - Step 4898, rl-loss: 207.16116333007812\r",
      "INFO - Step 4899, rl-loss: 63.6370735168457\r",
      "INFO - Step 4900, rl-loss: 100.60563659667969\r",
      "INFO - Step 4901, rl-loss: 203.77899169921875\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 4902, rl-loss: 113.90217590332031\r",
      "INFO - Step 4903, rl-loss: 298.88873291015625\r",
      "INFO - Step 4904, rl-loss: 514.6710815429688\r",
      "INFO - Step 4905, rl-loss: 72.6244888305664\r",
      "INFO - Step 4906, rl-loss: 46.69644546508789\r",
      "INFO - Step 4907, rl-loss: 71.56129455566406\r",
      "INFO - Step 4908, rl-loss: 301.1988525390625\r",
      "INFO - Step 4909, rl-loss: 45.105430603027344\r",
      "INFO - Step 4910, rl-loss: 62.7855110168457\r",
      "INFO - Step 4911, rl-loss: 99.5206069946289\r",
      "INFO - Step 4912, rl-loss: 271.4273681640625\r",
      "INFO - Step 4913, rl-loss: 98.88081359863281\r",
      "INFO - Step 4914, rl-loss: 77.58309936523438\r",
      "INFO - Step 4915, rl-loss: 153.27859497070312\r",
      "INFO - Step 4916, rl-loss: 106.12239074707031\r",
      "INFO - Step 4917, rl-loss: 348.9100646972656\r",
      "INFO - Step 4918, rl-loss: 333.0559997558594\r",
      "INFO - Step 4919, rl-loss: 74.716552734375\r",
      "INFO - Step 4920, rl-loss: 280.6668701171875\r",
      "INFO - Step 4921, rl-loss: 160.472900390625\r",
      "INFO - Step 4922, rl-loss: 29.594268798828125\r",
      "INFO - Step 4923, rl-loss: 155.71998596191406\r",
      "INFO - Step 4924, rl-loss: 121.07943725585938\r",
      "INFO - Step 4925, rl-loss: 245.7786865234375\r",
      "INFO - Step 4926, rl-loss: 120.05690002441406\r",
      "INFO - Step 4927, rl-loss: 54.86016082763672\r",
      "INFO - Step 4928, rl-loss: 164.41693115234375\r",
      "INFO - Step 4929, rl-loss: 440.2981872558594\r",
      "INFO - Step 4930, rl-loss: 49.33381652832031\r",
      "INFO - Step 4931, rl-loss: 237.87557983398438\r",
      "INFO - Step 4932, rl-loss: 133.1345977783203\r",
      "INFO - Step 4933, rl-loss: 500.32769775390625\r",
      "INFO - Step 4934, rl-loss: 72.80461883544922\r",
      "INFO - Step 4935, rl-loss: 175.48846435546875\r",
      "INFO - Step 4936, rl-loss: 114.74440002441406\r",
      "INFO - Step 4937, rl-loss: 47.91410446166992\r",
      "INFO - Step 4938, rl-loss: 113.37165832519531\r",
      "INFO - Step 4939, rl-loss: 107.50501251220703\r",
      "INFO - Step 4940, rl-loss: 203.51861572265625\r",
      "INFO - Step 4941, rl-loss: 353.9891052246094\r",
      "INFO - Step 4942, rl-loss: 86.474365234375\r",
      "INFO - Step 4943, rl-loss: 107.81787872314453\r",
      "INFO - Step 4944, rl-loss: 71.4616470336914\r",
      "INFO - Step 4945, rl-loss: 318.6444091796875\r",
      "INFO - Step 4946, rl-loss: 302.0763244628906\r",
      "INFO - Step 4947, rl-loss: 248.70550537109375\r",
      "INFO - Step 4948, rl-loss: 303.1708984375\r",
      "INFO - Step 4949, rl-loss: 103.97039794921875\r",
      "INFO - Step 4950, rl-loss: 36.88021469116211\r",
      "INFO - Step 4951, rl-loss: 555.6144409179688\r",
      "INFO - Step 4952, rl-loss: 90.53192901611328\r",
      "INFO - Step 4953, rl-loss: 100.09339904785156\r",
      "INFO - Step 4954, rl-loss: 107.05085754394531\r",
      "INFO - Step 4955, rl-loss: 102.47200012207031\r",
      "INFO - Step 4956, rl-loss: 306.3840637207031\r",
      "INFO - Step 4957, rl-loss: 44.720096588134766\r",
      "INFO - Step 4958, rl-loss: 411.55804443359375\r",
      "INFO - Step 4959, rl-loss: 67.33363342285156\r",
      "INFO - Step 4960, rl-loss: 537.127685546875\r",
      "INFO - Step 4961, rl-loss: 75.79020690917969\r",
      "INFO - Step 4962, rl-loss: 131.47386169433594\r",
      "INFO - Step 4963, rl-loss: 122.73365020751953\r",
      "INFO - Step 4964, rl-loss: 171.72543334960938\r",
      "INFO - Step 4965, rl-loss: 262.8167419433594\r",
      "INFO - Step 4966, rl-loss: 169.24111938476562\r",
      "INFO - Step 4967, rl-loss: 176.17001342773438\r",
      "INFO - Step 4968, rl-loss: 69.50126647949219\r",
      "INFO - Step 4969, rl-loss: 441.7010192871094\r",
      "INFO - Step 4970, rl-loss: 180.75311279296875\r",
      "INFO - Step 4971, rl-loss: 73.17459869384766\r",
      "INFO - Step 4972, rl-loss: 43.48131561279297\r",
      "INFO - Step 4973, rl-loss: 53.05201721191406\r",
      "INFO - Step 4974, rl-loss: 100.84426879882812\r",
      "INFO - Step 4975, rl-loss: 70.88546752929688\r",
      "INFO - Step 4976, rl-loss: 354.8681945800781\r",
      "INFO - Step 4977, rl-loss: 148.84231567382812\r",
      "INFO - Step 4978, rl-loss: 67.89669799804688\r",
      "INFO - Step 4979, rl-loss: 174.17930603027344\r",
      "INFO - Step 4980, rl-loss: 288.9513854980469\r",
      "INFO - Step 4981, rl-loss: 396.5332336425781\r",
      "INFO - Step 4982, rl-loss: 140.6775360107422\r",
      "INFO - Step 4983, rl-loss: 94.57510375976562\r",
      "INFO - Step 4984, rl-loss: 339.44342041015625\r",
      "INFO - Step 4985, rl-loss: 62.06110382080078\r",
      "INFO - Step 4986, rl-loss: 437.5533752441406\r",
      "INFO - Step 4987, rl-loss: 58.43159866333008\r",
      "INFO - Step 4988, rl-loss: 98.34133911132812\r",
      "INFO - Step 4989, rl-loss: 95.87648010253906\r",
      "INFO - Step 4990, rl-loss: 170.5186767578125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 93/25000 [00:09<36:20, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 4991, rl-loss: 107.82937622070312\r",
      "INFO - Step 4992, rl-loss: 145.36099243164062\r",
      "INFO - Step 4993, rl-loss: 52.466331481933594\r",
      "INFO - Step 4994, rl-loss: 82.09112548828125\r",
      "INFO - Step 4995, rl-loss: 60.56389617919922\r",
      "INFO - Step 4996, rl-loss: 122.34686279296875\r",
      "INFO - Step 4997, rl-loss: 61.137996673583984\r",
      "INFO - Step 4998, rl-loss: 51.52610778808594\r",
      "INFO - Step 4999, rl-loss: 162.0121307373047\r",
      "INFO - Step 5000, rl-loss: 111.99047088623047\r",
      "INFO - Step 5001, rl-loss: 194.02340698242188\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 5002, rl-loss: 88.7510986328125\r",
      "INFO - Step 5003, rl-loss: 475.4242248535156\r",
      "INFO - Step 5004, rl-loss: 257.9560241699219\r",
      "INFO - Step 5005, rl-loss: 220.286865234375\r",
      "INFO - Step 5006, rl-loss: 151.00604248046875\r",
      "INFO - Step 5007, rl-loss: 501.87652587890625\r",
      "INFO - Step 5008, rl-loss: 131.39865112304688\r",
      "INFO - Step 5009, rl-loss: 34.992706298828125\r",
      "INFO - Step 5010, rl-loss: 61.83868408203125\r",
      "INFO - Step 5011, rl-loss: 235.62509155273438\r",
      "INFO - Step 5012, rl-loss: 147.08297729492188\r",
      "INFO - Step 5013, rl-loss: 59.9476432800293\r",
      "INFO - Step 5014, rl-loss: 66.46858215332031\r",
      "INFO - Step 5015, rl-loss: 69.71807861328125\r",
      "INFO - Step 5016, rl-loss: 96.23482513427734\r",
      "INFO - Step 5017, rl-loss: 187.84703063964844\r",
      "INFO - Step 5018, rl-loss: 582.726806640625\r",
      "INFO - Step 5019, rl-loss: 265.27545166015625\r",
      "INFO - Step 5020, rl-loss: 414.3020935058594\r",
      "INFO - Step 5021, rl-loss: 154.3752899169922\r",
      "INFO - Step 5022, rl-loss: 236.8546600341797\r",
      "INFO - Step 5023, rl-loss: 45.823265075683594\r",
      "INFO - Step 5024, rl-loss: 236.61485290527344\r",
      "INFO - Step 5025, rl-loss: 122.79437255859375\r",
      "INFO - Step 5026, rl-loss: 193.01861572265625\r",
      "INFO - Step 5027, rl-loss: 73.82783508300781\r",
      "INFO - Step 5028, rl-loss: 272.0592041015625\r",
      "INFO - Step 5029, rl-loss: 238.26776123046875\r",
      "INFO - Step 5030, rl-loss: 299.070068359375\r",
      "INFO - Step 5031, rl-loss: 42.83416748046875\r",
      "INFO - Step 5032, rl-loss: 61.00919723510742\r",
      "INFO - Step 5033, rl-loss: 201.79641723632812\r",
      "INFO - Step 5034, rl-loss: 245.84036254882812\r",
      "INFO - Step 5035, rl-loss: 69.76941680908203\r",
      "INFO - Step 5036, rl-loss: 85.87548828125\r",
      "INFO - Step 5037, rl-loss: 177.3800048828125\r",
      "INFO - Step 5038, rl-loss: 120.86023712158203\r",
      "INFO - Step 5039, rl-loss: 285.1461181640625\r",
      "INFO - Step 5040, rl-loss: 72.30660247802734\r",
      "INFO - Step 5041, rl-loss: 209.3827667236328\r",
      "INFO - Step 5042, rl-loss: 231.2667694091797\r",
      "INFO - Step 5043, rl-loss: 91.80020904541016\r",
      "INFO - Step 5044, rl-loss: 143.09149169921875\r",
      "INFO - Step 5045, rl-loss: 164.08688354492188\r",
      "INFO - Step 5046, rl-loss: 117.57630157470703\r",
      "INFO - Step 5047, rl-loss: 87.94728088378906\r",
      "INFO - Step 5048, rl-loss: 347.1976623535156\r",
      "INFO - Step 5049, rl-loss: 88.90460968017578\r",
      "INFO - Step 5050, rl-loss: 90.50518798828125\r",
      "INFO - Step 5051, rl-loss: 161.58177185058594\r",
      "INFO - Step 5052, rl-loss: 218.0196075439453\r",
      "INFO - Step 5053, rl-loss: 269.2718200683594\r",
      "INFO - Step 5054, rl-loss: 148.05404663085938\r",
      "INFO - Step 5055, rl-loss: 95.37085723876953\r",
      "INFO - Step 5056, rl-loss: 72.42060852050781\r",
      "INFO - Step 5057, rl-loss: 289.789306640625\r",
      "INFO - Step 5058, rl-loss: 82.90988159179688\r",
      "INFO - Step 5059, rl-loss: 145.03749084472656\r",
      "INFO - Step 5060, rl-loss: 181.28756713867188\r",
      "INFO - Step 5061, rl-loss: 191.07032775878906\r",
      "INFO - Step 5062, rl-loss: 44.54962158203125\r",
      "INFO - Step 5063, rl-loss: 61.46247100830078\r",
      "INFO - Step 5064, rl-loss: 140.33529663085938\r",
      "INFO - Step 5065, rl-loss: 77.978759765625\r",
      "INFO - Step 5066, rl-loss: 106.35086059570312\r",
      "INFO - Step 5067, rl-loss: 103.48016357421875\r",
      "INFO - Step 5068, rl-loss: 345.34912109375\r",
      "INFO - Step 5069, rl-loss: 189.6668701171875\r",
      "INFO - Step 5070, rl-loss: 152.94578552246094\r",
      "INFO - Step 5071, rl-loss: 462.1634826660156\r",
      "INFO - Step 5072, rl-loss: 185.95738220214844\r",
      "INFO - Step 5073, rl-loss: 322.08441162109375\r",
      "INFO - Step 5074, rl-loss: 178.3133544921875\r",
      "INFO - Step 5075, rl-loss: 361.652587890625\r",
      "INFO - Step 5076, rl-loss: 70.7784652709961\r",
      "INFO - Step 5077, rl-loss: 66.54234313964844\r",
      "INFO - Step 5078, rl-loss: 52.59866714477539\r",
      "INFO - Step 5079, rl-loss: 254.18228149414062\r",
      "INFO - Step 5080, rl-loss: 94.92245483398438\r",
      "INFO - Step 5081, rl-loss: 75.18607330322266\r",
      "INFO - Step 5082, rl-loss: 71.94822692871094\r",
      "INFO - Step 5083, rl-loss: 71.69702911376953\r",
      "INFO - Step 5084, rl-loss: 168.5218963623047\r",
      "INFO - Step 5085, rl-loss: 660.8478393554688\r",
      "INFO - Step 5086, rl-loss: 76.55760955810547\r",
      "INFO - Step 5087, rl-loss: 96.43742370605469\r",
      "INFO - Step 5088, rl-loss: 281.7220153808594\r",
      "INFO - Step 5089, rl-loss: 268.7680969238281\r",
      "INFO - Step 5090, rl-loss: 69.11053466796875\r",
      "INFO - Step 5091, rl-loss: 65.60684204101562\r",
      "INFO - Step 5092, rl-loss: 148.16786193847656\r",
      "INFO - Step 5093, rl-loss: 313.4502258300781\r",
      "INFO - Step 5094, rl-loss: 200.61837768554688\r",
      "INFO - Step 5095, rl-loss: 70.92010498046875\r",
      "INFO - Step 5096, rl-loss: 335.42529296875\r",
      "INFO - Step 5097, rl-loss: 73.44114685058594\r",
      "INFO - Step 5098, rl-loss: 72.01142883300781\r",
      "INFO - Step 5099, rl-loss: 149.0215301513672\r",
      "INFO - Step 5100, rl-loss: 122.29772186279297\r",
      "INFO - Step 5101, rl-loss: 261.9733581542969\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 5102, rl-loss: 191.08914184570312\r",
      "INFO - Step 5103, rl-loss: 103.04852294921875\r",
      "INFO - Step 5104, rl-loss: 118.6319580078125\r",
      "INFO - Step 5105, rl-loss: 347.6965637207031\r",
      "INFO - Step 5106, rl-loss: 101.01434326171875\r",
      "INFO - Step 5107, rl-loss: 257.86370849609375\r",
      "INFO - Step 5108, rl-loss: 99.16084289550781\r",
      "INFO - Step 5109, rl-loss: 314.99224853515625\r",
      "INFO - Step 5110, rl-loss: 46.97673034667969\r",
      "INFO - Step 5111, rl-loss: 129.34747314453125\r",
      "INFO - Step 5112, rl-loss: 129.06581115722656\r",
      "INFO - Step 5113, rl-loss: 129.2392578125\r",
      "INFO - Step 5114, rl-loss: 251.49586486816406\r",
      "INFO - Step 5115, rl-loss: 143.79283142089844\r",
      "INFO - Step 5116, rl-loss: 43.75295639038086\r",
      "INFO - Step 5117, rl-loss: 289.783203125\r",
      "INFO - Step 5118, rl-loss: 261.83392333984375\r",
      "INFO - Step 5119, rl-loss: 94.65957641601562\r",
      "INFO - Step 5120, rl-loss: 302.16668701171875\r",
      "INFO - Step 5121, rl-loss: 163.1938934326172\r",
      "INFO - Step 5122, rl-loss: 87.74081420898438\r",
      "INFO - Step 5123, rl-loss: 367.83209228515625\r",
      "INFO - Step 5124, rl-loss: 259.9096984863281\r",
      "INFO - Step 5125, rl-loss: 58.25091552734375\r",
      "INFO - Step 5126, rl-loss: 85.40716552734375\r",
      "INFO - Step 5127, rl-loss: 174.12225341796875\r",
      "INFO - Step 5128, rl-loss: 136.1920623779297\r",
      "INFO - Step 5129, rl-loss: 175.25267028808594\r",
      "INFO - Step 5130, rl-loss: 148.633056640625\r",
      "INFO - Step 5131, rl-loss: 205.8819122314453\r",
      "INFO - Step 5132, rl-loss: 81.75761413574219\r",
      "INFO - Step 5133, rl-loss: 337.071044921875\r",
      "INFO - Step 5134, rl-loss: 239.93276977539062\r",
      "INFO - Step 5135, rl-loss: 116.93603515625\r",
      "INFO - Step 5136, rl-loss: 82.18380737304688\r",
      "INFO - Step 5137, rl-loss: 84.0897216796875\r",
      "INFO - Step 5138, rl-loss: 72.76531982421875\r",
      "INFO - Step 5139, rl-loss: 145.77964782714844\r",
      "INFO - Step 5140, rl-loss: 55.59565734863281\r",
      "INFO - Step 5141, rl-loss: 57.05375671386719\r",
      "INFO - Step 5142, rl-loss: 94.56584930419922\r",
      "INFO - Step 5143, rl-loss: 235.27255249023438\r",
      "INFO - Step 5144, rl-loss: 270.7510986328125\r",
      "INFO - Step 5145, rl-loss: 95.40336608886719\r",
      "INFO - Step 5146, rl-loss: 180.58868408203125\r",
      "INFO - Step 5147, rl-loss: 100.82846069335938\r",
      "INFO - Step 5148, rl-loss: 48.88655090332031\r",
      "INFO - Step 5149, rl-loss: 130.90127563476562\r",
      "INFO - Step 5150, rl-loss: 104.59373474121094\r",
      "INFO - Step 5151, rl-loss: 119.03860473632812\r",
      "INFO - Step 5152, rl-loss: 462.3304138183594\r",
      "INFO - Step 5153, rl-loss: 93.82105255126953\r",
      "INFO - Step 5154, rl-loss: 74.77801513671875\r",
      "INFO - Step 5155, rl-loss: 467.9953308105469\r",
      "INFO - Step 5156, rl-loss: 138.29063415527344\r",
      "INFO - Step 5157, rl-loss: 185.44979858398438\r",
      "INFO - Step 5158, rl-loss: 93.46751403808594\r",
      "INFO - Step 5159, rl-loss: 67.37541198730469\r",
      "INFO - Step 5160, rl-loss: 246.36611938476562\r",
      "INFO - Step 5161, rl-loss: 110.609619140625\r",
      "INFO - Step 5162, rl-loss: 192.6723175048828\r",
      "INFO - Step 5163, rl-loss: 93.33770751953125\r",
      "INFO - Step 5164, rl-loss: 108.50349426269531\r",
      "INFO - Step 5165, rl-loss: 132.632568359375\r",
      "INFO - Step 5166, rl-loss: 326.4444580078125\r",
      "INFO - Step 5167, rl-loss: 238.42141723632812\r",
      "INFO - Step 5168, rl-loss: 57.26321792602539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 101/25000 [00:10<39:18, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 5169, rl-loss: 97.91119384765625\r",
      "INFO - Step 5170, rl-loss: 309.92156982421875\r",
      "INFO - Step 5171, rl-loss: 95.69326782226562\r",
      "INFO - Step 5172, rl-loss: 84.1171875\r",
      "INFO - Step 5173, rl-loss: 285.19708251953125\r",
      "INFO - Step 5174, rl-loss: 140.20034790039062\r",
      "INFO - Step 5175, rl-loss: 68.65594482421875\r",
      "INFO - Step 5176, rl-loss: 72.7459716796875\r",
      "INFO - Step 5177, rl-loss: 179.98703002929688\r",
      "INFO - Step 5178, rl-loss: 187.90036010742188\r",
      "INFO - Step 5179, rl-loss: 260.0970458984375\r",
      "INFO - Step 5180, rl-loss: 54.80316162109375\r",
      "INFO - Step 5181, rl-loss: 66.06100463867188\r",
      "INFO - Step 5182, rl-loss: 99.04564666748047\r",
      "INFO - Step 5183, rl-loss: 55.69652557373047\r",
      "INFO - Step 5184, rl-loss: 364.3450927734375\r",
      "INFO - Step 5185, rl-loss: 202.3957977294922\r",
      "INFO - Step 5186, rl-loss: 188.4345245361328\r",
      "INFO - Step 5187, rl-loss: 92.56147003173828\r",
      "INFO - Step 5188, rl-loss: 120.25926208496094\r",
      "INFO - Step 5189, rl-loss: 415.08319091796875\r",
      "INFO - Step 5190, rl-loss: 61.866153717041016\r",
      "INFO - Step 5191, rl-loss: 78.15834045410156\r",
      "INFO - Step 5192, rl-loss: 146.86151123046875\r",
      "INFO - Step 5193, rl-loss: 120.04100036621094\r",
      "INFO - Step 5194, rl-loss: 244.66452026367188\r",
      "INFO - Step 5195, rl-loss: 61.31550598144531\r",
      "INFO - Step 5196, rl-loss: 283.21527099609375\r",
      "INFO - Step 5197, rl-loss: 77.61969757080078\r",
      "INFO - Step 5198, rl-loss: 232.29385375976562\r",
      "INFO - Step 5199, rl-loss: 244.32337951660156\r",
      "INFO - Step 5200, rl-loss: 275.6795959472656\r",
      "INFO - Step 5201, rl-loss: 175.64633178710938\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 5202, rl-loss: 421.79913330078125\r",
      "INFO - Step 5203, rl-loss: 40.104095458984375\r",
      "INFO - Step 5204, rl-loss: 312.6727294921875\r",
      "INFO - Step 5205, rl-loss: 89.53736877441406\r",
      "INFO - Step 5206, rl-loss: 144.5720977783203\r",
      "INFO - Step 5207, rl-loss: 76.17005920410156\r",
      "INFO - Step 5208, rl-loss: 339.1514587402344\r",
      "INFO - Step 5209, rl-loss: 146.7643280029297\r",
      "INFO - Step 5210, rl-loss: 175.71951293945312\r",
      "INFO - Step 5211, rl-loss: 160.90219116210938\r",
      "INFO - Step 5212, rl-loss: 227.41392517089844\r",
      "INFO - Step 5213, rl-loss: 273.2906188964844\r",
      "INFO - Step 5214, rl-loss: 82.25093078613281\r",
      "INFO - Step 5215, rl-loss: 183.37545776367188\r",
      "INFO - Step 5216, rl-loss: 56.859840393066406\r",
      "INFO - Step 5217, rl-loss: 112.74076843261719\r",
      "INFO - Step 5218, rl-loss: 84.79428100585938\r",
      "INFO - Step 5219, rl-loss: 142.99330139160156\r",
      "INFO - Step 5220, rl-loss: 65.01065063476562\r",
      "INFO - Step 5221, rl-loss: 389.1947326660156\r",
      "INFO - Step 5222, rl-loss: 136.20468139648438\r",
      "INFO - Step 5223, rl-loss: 97.30863189697266\r",
      "INFO - Step 5224, rl-loss: 42.99945068359375\r",
      "INFO - Step 5225, rl-loss: 374.91485595703125\r",
      "INFO - Step 5226, rl-loss: 101.19620513916016\r",
      "INFO - Step 5227, rl-loss: 147.14610290527344\r",
      "INFO - Step 5228, rl-loss: 139.56861877441406\r",
      "INFO - Step 5229, rl-loss: 69.13818359375\r",
      "INFO - Step 5230, rl-loss: 241.35841369628906\r",
      "INFO - Step 5231, rl-loss: 406.3717956542969\r",
      "INFO - Step 5232, rl-loss: 66.21124267578125\r",
      "INFO - Step 5233, rl-loss: 98.13255310058594\r",
      "INFO - Step 5234, rl-loss: 228.5487060546875\r",
      "INFO - Step 5235, rl-loss: 239.12255859375\r",
      "INFO - Step 5236, rl-loss: 185.53167724609375\r",
      "INFO - Step 5237, rl-loss: 187.83956909179688\r",
      "INFO - Step 5238, rl-loss: 54.286216735839844\r",
      "INFO - Step 5239, rl-loss: 234.23141479492188\r",
      "INFO - Step 5240, rl-loss: 252.19992065429688\r",
      "INFO - Step 5241, rl-loss: 166.9065704345703\r",
      "INFO - Step 5242, rl-loss: 297.3263244628906\r",
      "INFO - Step 5243, rl-loss: 133.48123168945312\r",
      "INFO - Step 5244, rl-loss: 93.28902435302734\r",
      "INFO - Step 5245, rl-loss: 238.14625549316406\r",
      "INFO - Step 5246, rl-loss: 157.9900665283203\r",
      "INFO - Step 5247, rl-loss: 231.5355224609375\r",
      "INFO - Step 5248, rl-loss: 124.55433654785156\r",
      "INFO - Step 5249, rl-loss: 427.4620056152344\r",
      "INFO - Step 5250, rl-loss: 122.53372955322266\r",
      "INFO - Step 5251, rl-loss: 303.92742919921875\r",
      "INFO - Step 5252, rl-loss: 102.04722595214844\r",
      "INFO - Step 5253, rl-loss: 251.94973754882812\r",
      "INFO - Step 5254, rl-loss: 248.2295684814453\r",
      "INFO - Step 5255, rl-loss: 203.71742248535156\r",
      "INFO - Step 5256, rl-loss: 223.39141845703125\r",
      "INFO - Step 5257, rl-loss: 163.3848876953125\r",
      "INFO - Step 5258, rl-loss: 183.27389526367188\r",
      "INFO - Step 5259, rl-loss: 495.70556640625\r",
      "INFO - Step 5260, rl-loss: 47.514190673828125\r",
      "INFO - Step 5261, rl-loss: 533.1061401367188\r",
      "INFO - Step 5262, rl-loss: 174.1219482421875\r",
      "INFO - Step 5263, rl-loss: 100.84971618652344\r",
      "INFO - Step 5264, rl-loss: 241.06671142578125\r",
      "INFO - Step 5265, rl-loss: 233.8782958984375\r",
      "INFO - Step 5266, rl-loss: 167.7413330078125\r",
      "INFO - Step 5267, rl-loss: 62.18657684326172\r",
      "INFO - Step 5268, rl-loss: 134.0517120361328\r",
      "INFO - Step 5269, rl-loss: 60.8811149597168\r",
      "INFO - Step 5270, rl-loss: 89.50121307373047\r",
      "INFO - Step 5271, rl-loss: 325.53411865234375\r",
      "INFO - Step 5272, rl-loss: 78.37571716308594\r",
      "INFO - Step 5273, rl-loss: 65.92930603027344\r",
      "INFO - Step 5274, rl-loss: 169.5213623046875\r",
      "INFO - Step 5275, rl-loss: 137.72789001464844\r",
      "INFO - Step 5276, rl-loss: 112.44635009765625\r",
      "INFO - Step 5277, rl-loss: 81.6434097290039\r",
      "INFO - Step 5278, rl-loss: 49.26515197753906\r",
      "INFO - Step 5279, rl-loss: 265.5348205566406\r",
      "INFO - Step 5280, rl-loss: 229.1527862548828\r",
      "INFO - Step 5281, rl-loss: 30.63840103149414\r",
      "INFO - Step 5282, rl-loss: 144.13626098632812\r",
      "INFO - Step 5283, rl-loss: 95.87229919433594\r",
      "INFO - Step 5284, rl-loss: 171.22015380859375\r",
      "INFO - Step 5285, rl-loss: 46.78313064575195\r",
      "INFO - Step 5286, rl-loss: 55.584388732910156\r",
      "INFO - Step 5287, rl-loss: 114.294921875\r",
      "INFO - Step 5288, rl-loss: 345.3370056152344\r",
      "INFO - Step 5289, rl-loss: 219.5179901123047\r",
      "INFO - Step 5290, rl-loss: 131.13247680664062\r",
      "INFO - Step 5291, rl-loss: 196.68099975585938\r",
      "INFO - Step 5292, rl-loss: 85.39582824707031\r",
      "INFO - Step 5293, rl-loss: 158.97740173339844\r",
      "INFO - Step 5294, rl-loss: 468.579345703125\r",
      "INFO - Step 5295, rl-loss: 290.13153076171875\r",
      "INFO - Step 5296, rl-loss: 124.55252838134766\r",
      "INFO - Step 5297, rl-loss: 81.3968734741211\r",
      "INFO - Step 5298, rl-loss: 113.71414184570312\r",
      "INFO - Step 5299, rl-loss: 140.96856689453125\r",
      "INFO - Step 5300, rl-loss: 133.5908660888672\r",
      "INFO - Step 5301, rl-loss: 190.32757568359375\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 5302, rl-loss: 133.77569580078125\r",
      "INFO - Step 5303, rl-loss: 81.39373016357422\r",
      "INFO - Step 5304, rl-loss: 38.87201690673828\r",
      "INFO - Step 5305, rl-loss: 390.0357360839844\r",
      "INFO - Step 5306, rl-loss: 62.252105712890625\r",
      "INFO - Step 5307, rl-loss: 207.7773895263672\r",
      "INFO - Step 5308, rl-loss: 394.03057861328125\r",
      "INFO - Step 5309, rl-loss: 241.16229248046875\r",
      "INFO - Step 5310, rl-loss: 255.02468872070312\r",
      "INFO - Step 5311, rl-loss: 267.6167907714844\r",
      "INFO - Step 5312, rl-loss: 58.3868408203125\r",
      "INFO - Step 5313, rl-loss: 74.29984283447266\r",
      "INFO - Step 5314, rl-loss: 110.44570922851562\r",
      "INFO - Step 5315, rl-loss: 74.09305572509766\r",
      "INFO - Step 5316, rl-loss: 77.42849731445312\r",
      "INFO - Step 5317, rl-loss: 131.0257110595703\r",
      "INFO - Step 5318, rl-loss: 211.41342163085938\r",
      "INFO - Step 5319, rl-loss: 46.170143127441406\r",
      "INFO - Step 5320, rl-loss: 75.18962097167969\r",
      "INFO - Step 5321, rl-loss: 172.85232543945312\r",
      "INFO - Step 5322, rl-loss: 98.15071105957031\r",
      "INFO - Step 5323, rl-loss: 109.50121307373047\r",
      "INFO - Step 5324, rl-loss: 44.67961120605469\r",
      "INFO - Step 5325, rl-loss: 78.07764434814453\r",
      "INFO - Step 5326, rl-loss: 175.0828094482422\r",
      "INFO - Step 5327, rl-loss: 94.18848419189453\r",
      "INFO - Step 5328, rl-loss: 190.93161010742188\r",
      "INFO - Step 5329, rl-loss: 280.58233642578125\r",
      "INFO - Step 5330, rl-loss: 160.2584686279297\r",
      "INFO - Step 5331, rl-loss: 69.34809875488281\r",
      "INFO - Step 5332, rl-loss: 279.614501953125\r",
      "INFO - Step 5333, rl-loss: 177.6660614013672\r",
      "INFO - Step 5334, rl-loss: 246.00506591796875\r",
      "INFO - Step 5335, rl-loss: 94.86895751953125\r",
      "INFO - Step 5336, rl-loss: 91.50299072265625\r",
      "INFO - Step 5337, rl-loss: 130.76768493652344\r",
      "INFO - Step 5338, rl-loss: 72.97932434082031\r",
      "INFO - Step 5339, rl-loss: 324.81292724609375\r",
      "INFO - Step 5340, rl-loss: 177.32162475585938\r",
      "INFO - Step 5341, rl-loss: 109.53367614746094\r",
      "INFO - Step 5342, rl-loss: 411.7682189941406\r",
      "INFO - Step 5343, rl-loss: 277.2591552734375\r",
      "INFO - Step 5344, rl-loss: 32.04607009887695\r",
      "INFO - Step 5345, rl-loss: 103.84941101074219\r",
      "INFO - Step 5346, rl-loss: 208.7501220703125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 107/25000 [00:10<36:38, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 5347, rl-loss: 420.58709716796875\r",
      "INFO - Step 5348, rl-loss: 67.91574096679688\r",
      "INFO - Step 5349, rl-loss: 89.86143493652344\r",
      "INFO - Step 5350, rl-loss: 130.46604919433594\r",
      "INFO - Step 5351, rl-loss: 58.989471435546875\r",
      "INFO - Step 5352, rl-loss: 151.7370147705078\r",
      "INFO - Step 5353, rl-loss: 315.8959655761719\r",
      "INFO - Step 5354, rl-loss: 93.79360961914062\r",
      "INFO - Step 5355, rl-loss: 231.35928344726562\r",
      "INFO - Step 5356, rl-loss: 41.92392349243164\r",
      "INFO - Step 5357, rl-loss: 98.35431671142578\r",
      "INFO - Step 5358, rl-loss: 211.34652709960938\r",
      "INFO - Step 5359, rl-loss: 172.5919189453125\r",
      "INFO - Step 5360, rl-loss: 237.66671752929688\r",
      "INFO - Step 5361, rl-loss: 255.45982360839844\r",
      "INFO - Step 5362, rl-loss: 188.81727600097656\r",
      "INFO - Step 5363, rl-loss: 451.16168212890625\r",
      "INFO - Step 5364, rl-loss: 322.8156433105469\r",
      "INFO - Step 5365, rl-loss: 156.51051330566406\r",
      "INFO - Step 5366, rl-loss: 142.09457397460938\r",
      "INFO - Step 5367, rl-loss: 390.0146179199219\r",
      "INFO - Step 5368, rl-loss: 72.81298828125\r",
      "INFO - Step 5369, rl-loss: 70.24708557128906\r",
      "INFO - Step 5370, rl-loss: 198.5410614013672\r",
      "INFO - Step 5371, rl-loss: 123.11282348632812\r",
      "INFO - Step 5372, rl-loss: 171.5357666015625\r",
      "INFO - Step 5373, rl-loss: 317.5860900878906\r",
      "INFO - Step 5374, rl-loss: 220.77284240722656\r",
      "INFO - Step 5375, rl-loss: 127.06820678710938\r",
      "INFO - Step 5376, rl-loss: 96.89106750488281\r",
      "INFO - Step 5377, rl-loss: 289.78900146484375\r",
      "INFO - Step 5378, rl-loss: 224.6868896484375\r",
      "INFO - Step 5379, rl-loss: 187.79425048828125\r",
      "INFO - Step 5380, rl-loss: 171.81500244140625\r",
      "INFO - Step 5381, rl-loss: 298.6688232421875\r",
      "INFO - Step 5382, rl-loss: 94.48121643066406\r",
      "INFO - Step 5383, rl-loss: 81.66908264160156\r",
      "INFO - Step 5384, rl-loss: 46.887210845947266\r",
      "INFO - Step 5385, rl-loss: 281.9285888671875\r",
      "INFO - Step 5386, rl-loss: 310.46826171875\r",
      "INFO - Step 5387, rl-loss: 66.61846923828125\r",
      "INFO - Step 5388, rl-loss: 133.62673950195312\r",
      "INFO - Step 5389, rl-loss: 257.11053466796875\r",
      "INFO - Step 5390, rl-loss: 49.525978088378906\r",
      "INFO - Step 5391, rl-loss: 221.34768676757812\r",
      "INFO - Step 5392, rl-loss: 50.256690979003906\r",
      "INFO - Step 5393, rl-loss: 245.53611755371094\r",
      "INFO - Step 5394, rl-loss: 337.74981689453125\r",
      "INFO - Step 5395, rl-loss: 60.280426025390625\r",
      "INFO - Step 5396, rl-loss: 84.98831176757812\r",
      "INFO - Step 5397, rl-loss: 162.81692504882812\r",
      "INFO - Step 5398, rl-loss: 147.9893341064453\r",
      "INFO - Step 5399, rl-loss: 135.55328369140625\r",
      "INFO - Step 5400, rl-loss: 248.96432495117188\r",
      "INFO - Step 5401, rl-loss: 189.82229614257812\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 5402, rl-loss: 373.32110595703125\r",
      "INFO - Step 5403, rl-loss: 99.638671875\r",
      "INFO - Step 5404, rl-loss: 88.83711242675781\r",
      "INFO - Step 5405, rl-loss: 68.42571258544922\r",
      "INFO - Step 5406, rl-loss: 79.29037475585938\r",
      "INFO - Step 5407, rl-loss: 74.616943359375\r",
      "INFO - Step 5408, rl-loss: 194.85397338867188\r",
      "INFO - Step 5409, rl-loss: 284.7730407714844\r",
      "INFO - Step 5410, rl-loss: 116.09781646728516\r",
      "INFO - Step 5411, rl-loss: 303.0523681640625\r",
      "INFO - Step 5412, rl-loss: 245.80224609375\r",
      "INFO - Step 5413, rl-loss: 150.31387329101562\r",
      "INFO - Step 5414, rl-loss: 193.78253173828125\r",
      "INFO - Step 5415, rl-loss: 243.73056030273438\r",
      "INFO - Step 5416, rl-loss: 151.75491333007812\r",
      "INFO - Step 5417, rl-loss: 58.571449279785156\r",
      "INFO - Step 5418, rl-loss: 68.42969512939453\r",
      "INFO - Step 5419, rl-loss: 302.216796875\r",
      "INFO - Step 5420, rl-loss: 170.94053649902344\r",
      "INFO - Step 5421, rl-loss: 211.5305633544922\r",
      "INFO - Step 5422, rl-loss: 204.0281524658203\r",
      "INFO - Step 5423, rl-loss: 249.89480590820312\r",
      "INFO - Step 5424, rl-loss: 252.6063690185547\r",
      "INFO - Step 5425, rl-loss: 144.13265991210938\r",
      "INFO - Step 5426, rl-loss: 390.52093505859375\r",
      "INFO - Step 5427, rl-loss: 316.91741943359375\r",
      "INFO - Step 5428, rl-loss: 189.99850463867188\r",
      "INFO - Step 5429, rl-loss: 75.29019165039062\r",
      "INFO - Step 5430, rl-loss: 184.400146484375\r",
      "INFO - Step 5431, rl-loss: 96.08368682861328\r",
      "INFO - Step 5432, rl-loss: 87.75631713867188\r",
      "INFO - Step 5433, rl-loss: 141.45082092285156\r",
      "INFO - Step 5434, rl-loss: 62.14087677001953\r",
      "INFO - Step 5435, rl-loss: 245.9833221435547\r",
      "INFO - Step 5436, rl-loss: 275.10430908203125\r",
      "INFO - Step 5437, rl-loss: 169.79248046875\r",
      "INFO - Step 5438, rl-loss: 110.22256469726562\r",
      "INFO - Step 5439, rl-loss: 137.70680236816406\r",
      "INFO - Step 5440, rl-loss: 67.251708984375\r",
      "INFO - Step 5441, rl-loss: 264.0411376953125\r",
      "INFO - Step 5442, rl-loss: 400.507568359375\r",
      "INFO - Step 5443, rl-loss: 84.06035614013672\r",
      "INFO - Step 5444, rl-loss: 135.69387817382812\r",
      "INFO - Step 5445, rl-loss: 274.7903137207031\r",
      "INFO - Step 5446, rl-loss: 366.1868896484375\r",
      "INFO - Step 5447, rl-loss: 47.043975830078125\r",
      "INFO - Step 5448, rl-loss: 159.56202697753906\r",
      "INFO - Step 5449, rl-loss: 402.5389404296875\r",
      "INFO - Step 5450, rl-loss: 268.7001037597656\r",
      "INFO - Step 5451, rl-loss: 193.78854370117188\r",
      "INFO - Step 5452, rl-loss: 171.2474822998047\r",
      "INFO - Step 5453, rl-loss: 191.0674285888672\r",
      "INFO - Step 5454, rl-loss: 352.0965881347656\r",
      "INFO - Step 5455, rl-loss: 293.33282470703125\r",
      "INFO - Step 5456, rl-loss: 85.92707824707031\r",
      "INFO - Step 5457, rl-loss: 177.28009033203125\r",
      "INFO - Step 5458, rl-loss: 161.31903076171875\r",
      "INFO - Step 5459, rl-loss: 212.4552001953125\r",
      "INFO - Step 5460, rl-loss: 266.12799072265625\r",
      "INFO - Step 5461, rl-loss: 160.61509704589844\r",
      "INFO - Step 5462, rl-loss: 73.16521453857422\r",
      "INFO - Step 5463, rl-loss: 79.75200653076172\r",
      "INFO - Step 5464, rl-loss: 54.17070770263672\r",
      "INFO - Step 5465, rl-loss: 209.40008544921875\r",
      "INFO - Step 5466, rl-loss: 276.9710998535156\r",
      "INFO - Step 5467, rl-loss: 217.6283721923828\r",
      "INFO - Step 5468, rl-loss: 159.5668487548828\r",
      "INFO - Step 5469, rl-loss: 310.80670166015625\r",
      "INFO - Step 5470, rl-loss: 168.3515625\r",
      "INFO - Step 5471, rl-loss: 240.02366638183594\r",
      "INFO - Step 5472, rl-loss: 70.18680572509766\r",
      "INFO - Step 5473, rl-loss: 78.39246368408203\r",
      "INFO - Step 5474, rl-loss: 262.0521240234375\r",
      "INFO - Step 5475, rl-loss: 173.24240112304688\r",
      "INFO - Step 5476, rl-loss: 106.09254455566406\r",
      "INFO - Step 5477, rl-loss: 426.8670654296875\r",
      "INFO - Step 5478, rl-loss: 140.09002685546875\r",
      "INFO - Step 5479, rl-loss: 253.0560302734375\r",
      "INFO - Step 5480, rl-loss: 217.57916259765625\r",
      "INFO - Step 5481, rl-loss: 89.77902221679688\r",
      "INFO - Step 5482, rl-loss: 170.05523681640625\r",
      "INFO - Step 5483, rl-loss: 450.1872863769531\r",
      "INFO - Step 5484, rl-loss: 154.81756591796875\r",
      "INFO - Step 5485, rl-loss: 153.8858184814453\r",
      "INFO - Step 5486, rl-loss: 116.16828918457031\r",
      "INFO - Step 5487, rl-loss: 101.58009338378906\r",
      "INFO - Step 5488, rl-loss: 292.3296813964844\r",
      "INFO - Step 5489, rl-loss: 298.672119140625\r",
      "INFO - Step 5490, rl-loss: 232.74331665039062\r",
      "INFO - Step 5491, rl-loss: 265.04931640625\r",
      "INFO - Step 5492, rl-loss: 134.11965942382812\r",
      "INFO - Step 5493, rl-loss: 391.40533447265625\r",
      "INFO - Step 5494, rl-loss: 231.9298095703125\r",
      "INFO - Step 5495, rl-loss: 57.28447723388672\r",
      "INFO - Step 5496, rl-loss: 206.86878967285156\r",
      "INFO - Step 5497, rl-loss: 133.7432403564453\r",
      "INFO - Step 5498, rl-loss: 62.682861328125\r",
      "INFO - Step 5499, rl-loss: 43.217735290527344\r",
      "INFO - Step 5500, rl-loss: 135.14999389648438\r",
      "INFO - Step 5501, rl-loss: 243.25802612304688\n",
      "INFO - Copied model parameters to target network.\n",
      "\r",
      "INFO - Step 5502, rl-loss: 220.47854614257812\r",
      "INFO - Step 5503, rl-loss: 80.96188354492188\r",
      "INFO - Step 5504, rl-loss: 449.305908203125\r",
      "INFO - Step 5505, rl-loss: 265.888671875\r",
      "INFO - Step 5506, rl-loss: 61.79130935668945\r",
      "INFO - Step 5507, rl-loss: 96.83391571044922\r",
      "INFO - Step 5508, rl-loss: 179.64627075195312\r",
      "INFO - Step 5509, rl-loss: 126.52375793457031\r",
      "INFO - Step 5510, rl-loss: 165.04005432128906\r",
      "INFO - Step 5511, rl-loss: 160.98483276367188\r",
      "INFO - Step 5512, rl-loss: 163.33624267578125\r",
      "INFO - Step 5513, rl-loss: 517.89013671875\r",
      "INFO - Step 5514, rl-loss: 48.771697998046875\r",
      "INFO - Step 5515, rl-loss: 53.97967529296875\r",
      "INFO - Step 5516, rl-loss: 186.3397674560547\r",
      "INFO - Step 5517, rl-loss: 207.4305877685547\r",
      "INFO - Step 5518, rl-loss: 146.56072998046875\r",
      "INFO - Step 5519, rl-loss: 87.19232177734375\r",
      "INFO - Step 5520, rl-loss: 249.48989868164062\r",
      "INFO - Step 5521, rl-loss: 188.5091094970703\r",
      "INFO - Step 5522, rl-loss: 63.79754638671875\r",
      "INFO - Step 5523, rl-loss: 83.90011596679688\r",
      "INFO - Step 5524, rl-loss: 88.34039306640625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 109/25000 [00:10<41:22, 10.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_249/2727308937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Number of episodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrajectories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayoffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Assuming 'payoffs' are the game outcomes for each player\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/rlcard/envs/env.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, is_training)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# Environment steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_player_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0;31m# Save action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mtrajectories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplayer_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/rlcard/envs/env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action, raw_action)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/rlcard/envs/uno.py\u001b[0m in \u001b[0;36m_extract_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mencode_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hand'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mencode_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlegal_action_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_legal_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/rlcard/games/uno/utils.py\u001b[0m in \u001b[0;36mencode_hand\u001b[0;34m(plane, hand)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mhand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhand2dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mcard_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOLOR_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcard_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mtrait\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRAIT_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcard_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "INFO - Step 5525, rl-loss: 237.54005432128906\r",
      "INFO - Step 5526, rl-loss: 247.93051147460938\r",
      "INFO - Step 5527, rl-loss: 73.07599639892578\r",
      "INFO - Step 5528, rl-loss: 76.84397888183594\r",
      "INFO - Step 5529, rl-loss: 66.43702697753906\r",
      "INFO - Step 5530, rl-loss: 96.94234466552734\r",
      "INFO - Step 5531, rl-loss: 259.673828125\r",
      "INFO - Step 5532, rl-loss: 278.6844177246094\r",
      "INFO - Step 5533, rl-loss: 156.12989807128906\r",
      "INFO - Step 5534, rl-loss: 120.23167419433594\r",
      "INFO - Step 5535, rl-loss: 678.0908203125\r",
      "INFO - Step 5536, rl-loss: 253.52102661132812\r",
      "INFO - Step 5537, rl-loss: 258.60516357421875\r",
      "INFO - Step 5538, rl-loss: 289.50445556640625\r",
      "INFO - Step 5539, rl-loss: 142.77752685546875\r",
      "INFO - Step 5540, rl-loss: 279.8894958496094\r",
      "INFO - Step 5541, rl-loss: 138.52671813964844\r",
      "INFO - Step 5542, rl-loss: 90.2581558227539\r",
      "INFO - Step 5543, rl-loss: 158.94236755371094\r",
      "INFO - Step 5544, rl-loss: 185.2816162109375\r",
      "INFO - Step 5545, rl-loss: 74.03421783447266\r",
      "INFO - Step 5546, rl-loss: 249.46209716796875\r",
      "INFO - Step 5547, rl-loss: 74.3058090209961\r",
      "INFO - Step 5548, rl-loss: 293.0751647949219\r",
      "INFO - Step 5549, rl-loss: 186.59652709960938\r",
      "INFO - Step 5550, rl-loss: 284.3360290527344\r",
      "INFO - Step 5551, rl-loss: 58.52667999267578\r",
      "INFO - Step 5552, rl-loss: 129.78543090820312\r",
      "INFO - Step 5553, rl-loss: 277.39398193359375\r",
      "INFO - Step 5554, rl-loss: 87.7730712890625\r",
      "INFO - Step 5555, rl-loss: 313.02642822265625\r",
      "INFO - Step 5556, rl-loss: 180.607177734375\r",
      "INFO - Step 5557, rl-loss: 186.74407958984375\r",
      "INFO - Step 5558, rl-loss: 165.4121856689453\r",
      "INFO - Step 5559, rl-loss: 90.50172424316406\r",
      "INFO - Step 5560, rl-loss: 154.4695587158203\r",
      "INFO - Step 5561, rl-loss: 102.07968139648438\r",
      "INFO - Step 5562, rl-loss: 26.998937606811523\r",
      "INFO - Step 5563, rl-loss: 323.2628173828125\r",
      "INFO - Step 5564, rl-loss: 56.3699951171875\r",
      "INFO - Step 5565, rl-loss: 82.01828002929688\r",
      "INFO - Step 5566, rl-loss: 147.05044555664062\r",
      "INFO - Step 5567, rl-loss: 182.14402770996094\r",
      "INFO - Step 5568, rl-loss: 69.78208923339844\r",
      "INFO - Step 5569, rl-loss: 463.7412414550781\r",
      "INFO - Step 5570, rl-loss: 76.00079345703125\r",
      "INFO - Step 5571, rl-loss: 287.72003173828125\r",
      "INFO - Step 5572, rl-loss: 190.13343811035156\r",
      "INFO - Step 5573, rl-loss: 97.61907958984375\r",
      "INFO - Step 5574, rl-loss: 121.64630126953125\r",
      "INFO - Step 5575, rl-loss: 80.85728454589844\r",
      "INFO - Step 5576, rl-loss: 113.65367126464844\r",
      "INFO - Step 5577, rl-loss: 144.0047607421875\r",
      "INFO - Step 5578, rl-loss: 246.93252563476562\r",
      "INFO - Step 5579, rl-loss: 262.1818542480469\r",
      "INFO - Step 5580, rl-loss: 189.95883178710938\n",
      "Logs saved in ./experiments/uno_dqn_result/\n"
     ]
    }
   ],
   "source": [
    "episode_num = 25000  # Number of episodes \n",
    "\n",
    "evaluate_every = 1000 # Evaluate the agent every X episodes\n",
    "evaluate_num = 100  # Number of games played in evaluation\n",
    "\n",
    "with Logger(log_dir) as logger:\n",
    "    for episode in tqdm(range(episode_num)):  # Number of episodes\n",
    "\n",
    "        trajectories, payoffs = env.run(is_training=True)\n",
    "\n",
    "        # Assuming 'payoffs' are the game outcomes for each player\n",
    "        for i, payoff in enumerate(payoffs):\n",
    "            if payoff > 0:  # Assuming a positive payoff means winning\n",
    "                payoffs[i] = 100\n",
    "            else:\n",
    "                payoffs[i] = -25\n",
    "\n",
    "        trajectories = reorganize(trajectories, payoffs)\n",
    "\n",
    "        # After reorganizing the trajectories, adjust the rewards\n",
    "        trajectories = adjust_rewards(trajectories, payoffs)\n",
    "        # print(trajectories[0])\n",
    "\n",
    "        for ts in trajectories[0]:\n",
    "            agent.feed(ts)\n",
    "        \n",
    "        if episode % evaluate_every == 0:\n",
    "                block()\n",
    "                logger.log_performance(\n",
    "                    episode,\n",
    "                    tournament(\n",
    "                        env,\n",
    "                        evaluate_num,\n",
    "                    )[0]\n",
    "                )\n",
    "                \n",
    "                unblock()\n",
    "\n",
    "    # Get the paths\n",
    "    csv_path, fig_path = logger.csv_path, logger.fig_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Agent\n",
    "After training, evaluate your agent's performance. You can use RLCard's tournament function to play the game multiple times and see how well your agent performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "plot_curve(csv_path, fig_path, \"dqn\")\n",
    "\n",
    "# Save model\n",
    "save_path = os.path.join(log_dir, 'model.pth')\n",
    "torch.save(agent, save_path)\n",
    "print('Model saved in', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
